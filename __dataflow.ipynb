{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from utils import timer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features,hidden_dim,out_features, num_hidden_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(in_features, hidden_dim))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Linear(hidden_dim, out_features))\n",
    "        self.layers.append(nn.Softmax(dim=1))\n",
    "\n",
    "        self.connections = (num_hidden_layers-1)* hidden_dim**2 + hidden_dim*(in_features+out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "def run(args):\n",
    "    num_epochs = args.num_epochs\n",
    "    batch_size = args.batch_size    \n",
    "\n",
    "    print(args)\n",
    "    x, y = datasets.fetch_covtype(return_X_y=True)\n",
    "    num_samples = args.sample_portion * x.shape[0]\n",
    "    learning_rate = math.sqrt(batch_size/num_samples)*0.01\n",
    "    \n",
    "    model = MLP(in_features=x.shape[1], hidden_dim=99, out_features=7, num_hidden_layers=3)\n",
    "    print(f'model in_features: {x.shape[1]}, hidden_dim: 99, out_features: 7, num_hidden_layers: 3, num_samples: {num_samples},leanring_rate: {learning_rate}')\n",
    "    \n",
    "    #GFLO\n",
    "    num_connections  = model.connections\n",
    "    GFLO = num_epochs*6*num_samples*num_connections / 1e9\n",
    "    print(f\"GFLO is {GFLO:.2f}, should take {GFLO/(5000 * 0.3):.2f} seconds on a 5 TFLOPS machine\")\n",
    "\n",
    "    # load data \n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "    y = F.one_hot(y-1, num_classes=7).to(torch.float32)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # move data and model to GPU\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    dataset = TensorDataset(x, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=args.batch_size, shuffle=args.shuffle)\n",
    "\n",
    "    print('start training the model')\n",
    "    epoch_timer = timer.Timer()\n",
    "    test_timer = timer.Timer()\n",
    "\n",
    "    loss = criterion(y*0,y)\n",
    "    print(f'Initial Loss: {loss.item():.10f}')\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_timer.start()\n",
    "        if args.data_loader==2:\n",
    "            for i, (batch_x, batch_y) in enumerate(dataloader):\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()              \n",
    "        elif args.data_loader==1:\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                batch_x = x[i:i+batch_size]\n",
    "                batch_y = y[i:i+batch_size]\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        else:\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        if (epoch<10)| ((epoch+1) % 10 == 0) :\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.10f}')\n",
    "        epoch_timer.end()        \n",
    "    print('finished training the model')\n",
    "\n",
    "    test_timer.start()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(x)\n",
    "        test_loss = criterion(test_outputs, y)\n",
    "        print(f'Test Loss: {test_loss.item():.10f}')\n",
    "    test_timer.end()\n",
    "    print(f'epoch : {epoch_timer.get_average_time()}, total : {epoch_timer.get_total_time()}, test : {test_timer.get_average_time()}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arg :\n",
    "    def __init__(self):\n",
    "        self.num_epochs = 300\n",
    "        self.sample_portion = 1\n",
    "        self.data_loader = 0\n",
    "        self.batch_size = 16384\n",
    "        self.shuffle = False\n",
    "\n",
    "args = Arg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Arg object at 0x000001FBE7A854C0>\n",
      "model in_features: 54, hidden_dim: 99, out_features: 7, num_hidden_layers: 3, num_samples: 581012,leanring_rate: 0.0016792579712777344\n",
      "GFLO is 26815.91, should take 17.88 seconds on a 5 TFLOPS machine\n",
      "start training the model\n",
      "Initial Loss: 1.9459103346\n",
      "Epoch [1/300], Loss: 2.0612566471\n",
      "Epoch [2/300], Loss: 1.8008165359\n",
      "Epoch [3/300], Loss: 1.8008171320\n",
      "Epoch [4/300], Loss: 1.8008171320\n",
      "Epoch [5/300], Loss: 1.8008171320\n",
      "Epoch [6/300], Loss: 1.8008171320\n",
      "Epoch [7/300], Loss: 1.8008171320\n",
      "Epoch [8/300], Loss: 1.8008171320\n",
      "Epoch [9/300], Loss: 1.8008171320\n",
      "Epoch [10/300], Loss: 1.8008171320\n",
      "Epoch [20/300], Loss: 1.8008171320\n",
      "Epoch [30/300], Loss: 1.8008171320\n",
      "Epoch [40/300], Loss: 1.8008171320\n",
      "Epoch [50/300], Loss: 1.8008171320\n",
      "Epoch [60/300], Loss: 1.8008171320\n",
      "Epoch [70/300], Loss: 1.8008171320\n",
      "Epoch [80/300], Loss: 1.8008171320\n",
      "Epoch [90/300], Loss: 1.8008171320\n",
      "Epoch [100/300], Loss: 1.8008171320\n",
      "Epoch [110/300], Loss: 1.8008171320\n",
      "Epoch [120/300], Loss: 1.8008171320\n",
      "Epoch [130/300], Loss: 1.8008171320\n",
      "Epoch [140/300], Loss: 1.8008171320\n",
      "Epoch [150/300], Loss: 1.8008171320\n",
      "Epoch [160/300], Loss: 1.8008171320\n",
      "Epoch [170/300], Loss: 1.8008171320\n",
      "Epoch [180/300], Loss: 1.8008171320\n",
      "Epoch [190/300], Loss: 1.8008171320\n",
      "Epoch [200/300], Loss: 1.8008171320\n",
      "Epoch [210/300], Loss: 1.8008171320\n",
      "Epoch [220/300], Loss: 1.8008171320\n",
      "Epoch [230/300], Loss: 1.8008171320\n",
      "Epoch [240/300], Loss: 1.8008171320\n",
      "Epoch [250/300], Loss: 1.8008171320\n",
      "Epoch [260/300], Loss: 1.8008171320\n",
      "Epoch [270/300], Loss: 1.8008171320\n",
      "Epoch [280/300], Loss: 1.8008171320\n",
      "Epoch [290/300], Loss: 1.8008171320\n",
      "Epoch [300/300], Loss: 1.8008171320\n",
      "finished training the model\n",
      "Test Loss: 1.8008171320\n",
      "epoch : 0.04479166666666667, total : 13.4375, test : 0.015625\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        10.34%        2.234s        98.52%       21.284s       21.284s             1  \n",
      "                                             aten::item         0.01%       2.881ms        75.89%       16.395s       3.385ms          4843  \n",
      "                              aten::_local_scalar_dense        75.88%       16.392s        75.88%       16.392s       3.385ms          4843  \n",
      "                                               aten::to         0.00%     300.000us         6.08%        1.314s       2.109ms           623  \n",
      "                                         aten::_to_copy         0.00%     189.000us         6.08%        1.314s     101.042ms            13  \n",
      "                                    aten::empty_strided         5.88%        1.271s         5.88%        1.271s     465.586us          2729  \n",
      "                                           aten::linear         0.03%       7.377ms         4.49%     969.682ms     805.384us          1204  \n",
      "                                            aten::addmm         4.38%     945.773ms         4.39%     949.407ms     788.544us          1204  \n",
      "    autograd::engine::evaluate_function: AddmmBackward0         0.09%      19.154ms         0.86%     185.416ms     154.513us          1200  \n",
      "                               Optimizer.step#Adam.step         0.44%      95.739ms         0.84%     181.701ms     605.670us           300  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 21.602s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        run(args)\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
