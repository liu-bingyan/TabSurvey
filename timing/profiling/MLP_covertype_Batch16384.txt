Namespace(config='config/covertype.yml', model_name='MLP', dataset='Covertype', objective='classification', use_gpu=True, gpu_ids=[0, 1], data_parallel=False, optimize_hyperparameters=False, n_trials=5, direction='minimize', num_splits=5, shuffle=True, seed=221, scale=True, target_encode=True, one_hot_encode=False, batch_size=16384, val_batch_size=16384, early_stopping_rounds=400, epochs=400, logging_period=100, num_features=54, num_classes=7, cat_idx=None, cat_dims=None)
Train model with given hyperparameters
Loading dataset Covertype...
Dataset loaded!
(581012, 54)
Having 7 classes as target.
Scaling the data...
On Device: cuda
On Device: cuda
Epoch 0, Val Loss: 1.84431
Epoch 1, Val Loss: 1.70798
Epoch 2, Val Loss: 1.68631
Epoch 3, Val Loss: 1.65691
Epoch 4, Val Loss: 1.62250
Epoch 5, Val Loss: 1.60902
Epoch 6, Val Loss: 1.59920
Epoch 7, Val Loss: 1.58993
Epoch 8, Val Loss: 1.58081
Epoch 9, Val Loss: 1.57517
Epoch 10, Val Loss: 1.57272
Epoch 11, Val Loss: 1.57064
Epoch 12, Val Loss: 1.56804
Epoch 13, Val Loss: 1.56673
Epoch 14, Val Loss: 1.56660
Epoch 15, Val Loss: 1.56475
Epoch 16, Val Loss: 1.56372
Epoch 17, Val Loss: 1.56411
Epoch 18, Val Loss: 1.56311
Epoch 19, Val Loss: 1.56180
Epoch 20, Val Loss: 1.56238
Epoch 21, Val Loss: 1.56160
Epoch 22, Val Loss: 1.56024
Epoch 23, Val Loss: 1.56094
Epoch 24, Val Loss: 1.56041
Epoch 25, Val Loss: 1.55887
Epoch 26, Val Loss: 1.55938
Epoch 27, Val Loss: 1.55929
Epoch 28, Val Loss: 1.55760
Epoch 29, Val Loss: 1.55786
Epoch 30, Val Loss: 1.55711
Epoch 31, Val Loss: 1.55625
Epoch 32, Val Loss: 1.55563
Epoch 33, Val Loss: 1.55583
Epoch 34, Val Loss: 1.55374
Epoch 35, Val Loss: 1.55445
Epoch 36, Val Loss: 1.55302
Epoch 37, Val Loss: 1.55410
Epoch 38, Val Loss: 1.55252
Epoch 39, Val Loss: 1.55376
Epoch 40, Val Loss: 1.55187
Epoch 41, Val Loss: 1.55298
Epoch 42, Val Loss: 1.55128
Epoch 43, Val Loss: 1.55243
Epoch 44, Val Loss: 1.55067
Epoch 45, Val Loss: 1.55156
Epoch 46, Val Loss: 1.55031
Epoch 47, Val Loss: 1.55080
Epoch 48, Val Loss: 1.54995
Epoch 49, Val Loss: 1.55003
Epoch 50, Val Loss: 1.54951
Epoch 51, Val Loss: 1.54960
Epoch 52, Val Loss: 1.54912
Epoch 53, Val Loss: 1.54929
Epoch 54, Val Loss: 1.54858
Epoch 55, Val Loss: 1.54898
Epoch 56, Val Loss: 1.54823
Epoch 57, Val Loss: 1.54874
Epoch 58, Val Loss: 1.54793
Epoch 59, Val Loss: 1.54852
Epoch 60, Val Loss: 1.54759
Epoch 61, Val Loss: 1.54817
Epoch 62, Val Loss: 1.54728
Epoch 63, Val Loss: 1.54787
Epoch 64, Val Loss: 1.54699
Epoch 65, Val Loss: 1.54749
Epoch 66, Val Loss: 1.54667
Epoch 67, Val Loss: 1.54680
Epoch 68, Val Loss: 1.54637
Epoch 69, Val Loss: 1.54626
Epoch 70, Val Loss: 1.54606
Epoch 71, Val Loss: 1.54593
Epoch 72, Val Loss: 1.54576
Epoch 73, Val Loss: 1.54553
Epoch 74, Val Loss: 1.54542
Epoch 75, Val Loss: 1.54512
Epoch 76, Val Loss: 1.54490
Epoch 77, Val Loss: 1.54493
Epoch 78, Val Loss: 1.54456
Epoch 79, Val Loss: 1.54459
Epoch 80, Val Loss: 1.54455
Epoch 81, Val Loss: 1.54459
Epoch 82, Val Loss: 1.54440
Epoch 83, Val Loss: 1.54445
Epoch 84, Val Loss: 1.54442
Epoch 85, Val Loss: 1.54472
Epoch 86, Val Loss: 1.54455
Epoch 87, Val Loss: 1.54492
Epoch 88, Val Loss: 1.54537
Epoch 89, Val Loss: 1.54542
Epoch 90, Val Loss: 1.54532
Epoch 91, Val Loss: 1.54439
Epoch 92, Val Loss: 1.54546
Epoch 93, Val Loss: 1.54554
Epoch 94, Val Loss: 1.54343
Epoch 95, Val Loss: 1.54190
Epoch 96, Val Loss: 1.54319
Epoch 97, Val Loss: 1.54354
Epoch 98, Val Loss: 1.54293
Epoch 99, Val Loss: 1.54408
Epoch 100, Val Loss: 1.54171
Epoch 101, Val Loss: 1.54044
Epoch 102, Val Loss: 1.54248
Epoch 103, Val Loss: 1.54328
Epoch 104, Val Loss: 1.54184
Epoch 105, Val Loss: 1.54226
Epoch 106, Val Loss: 1.54315
Epoch 107, Val Loss: 1.54041
Epoch 108, Val Loss: 1.53987
Epoch 109, Val Loss: 1.54102
Epoch 110, Val Loss: 1.54229
Epoch 111, Val Loss: 1.54202
Epoch 112, Val Loss: 1.54104
Epoch 113, Val Loss: 1.54080
Epoch 114, Val Loss: 1.54217
Epoch 115, Val Loss: 1.53981
Epoch 116, Val Loss: 1.53957
Epoch 117, Val Loss: 1.54175
Epoch 118, Val Loss: 1.53974
Epoch 119, Val Loss: 1.53858
Epoch 120, Val Loss: 1.54120
Epoch 121, Val Loss: 1.54005
Epoch 122, Val Loss: 1.53981
Epoch 123, Val Loss: 1.54198
Epoch 124, Val Loss: 1.54003
Epoch 125, Val Loss: 1.53819
Epoch 126, Val Loss: 1.54025
Epoch 127, Val Loss: 1.54318
Epoch 128, Val Loss: 1.54147
Epoch 129, Val Loss: 1.54218
Epoch 130, Val Loss: 1.53845
Epoch 131, Val Loss: 1.53842
Epoch 132, Val Loss: 1.53776
Epoch 133, Val Loss: 1.54098
Epoch 134, Val Loss: 1.54041
Epoch 135, Val Loss: 1.53918
Epoch 136, Val Loss: 1.53835
Epoch 137, Val Loss: 1.53956
Epoch 138, Val Loss: 1.53805
Epoch 139, Val Loss: 1.54040
Epoch 140, Val Loss: 1.53701
Epoch 141, Val Loss: 1.53708
Epoch 142, Val Loss: 1.53640
Epoch 143, Val Loss: 1.53744
Epoch 144, Val Loss: 1.53544
Epoch 145, Val Loss: 1.53773
Epoch 146, Val Loss: 1.53546
Epoch 147, Val Loss: 1.53609
Epoch 148, Val Loss: 1.53666
Epoch 149, Val Loss: 1.53648
Epoch 150, Val Loss: 1.53820
Epoch 151, Val Loss: 1.53917
Epoch 152, Val Loss: 1.53889
Epoch 153, Val Loss: 1.53839
Epoch 154, Val Loss: 1.53773
Epoch 155, Val Loss: 1.53733
Epoch 156, Val Loss: 1.53503
Epoch 157, Val Loss: 1.53492
Epoch 158, Val Loss: 1.53776
Epoch 159, Val Loss: 1.53905
Epoch 160, Val Loss: 1.53782
Epoch 161, Val Loss: 1.53918
Epoch 162, Val Loss: 1.53466
Epoch 163, Val Loss: 1.53431
Epoch 164, Val Loss: 1.53390
Epoch 165, Val Loss: 1.53484
Epoch 166, Val Loss: 1.53738
Epoch 167, Val Loss: 1.53923
Epoch 168, Val Loss: 1.53547
Epoch 169, Val Loss: 1.53886
Epoch 170, Val Loss: 1.53275
Epoch 171, Val Loss: 1.53325
Epoch 172, Val Loss: 1.53559
Epoch 173, Val Loss: 1.53785
Epoch 174, Val Loss: 1.53469
Epoch 175, Val Loss: 1.53845
Epoch 176, Val Loss: 1.53252
Epoch 177, Val Loss: 1.53373
Epoch 178, Val Loss: 1.53449
Epoch 179, Val Loss: 1.53728
Epoch 180, Val Loss: 1.53250
Epoch 181, Val Loss: 1.53477
Epoch 182, Val Loss: 1.53233
Epoch 183, Val Loss: 1.53495
Epoch 184, Val Loss: 1.53244
Epoch 185, Val Loss: 1.53488
Epoch 186, Val Loss: 1.53305
Epoch 187, Val Loss: 1.53459
Epoch 188, Val Loss: 1.53237
Epoch 189, Val Loss: 1.53376
Epoch 190, Val Loss: 1.53169
Epoch 191, Val Loss: 1.53328
Epoch 192, Val Loss: 1.53286
Epoch 193, Val Loss: 1.53424
Epoch 194, Val Loss: 1.53300
Epoch 195, Val Loss: 1.53377
Epoch 196, Val Loss: 1.53055
Epoch 197, Val Loss: 1.53137
Epoch 198, Val Loss: 1.53117
Epoch 199, Val Loss: 1.53478
Epoch 200, Val Loss: 1.53143
Epoch 201, Val Loss: 1.53458
Epoch 202, Val Loss: 1.53062
Epoch 203, Val Loss: 1.53093
Epoch 204, Val Loss: 1.52926
Epoch 205, Val Loss: 1.52885
Epoch 206, Val Loss: 1.53110
Epoch 207, Val Loss: 1.53160
Epoch 208, Val Loss: 1.52881
Epoch 209, Val Loss: 1.53287
Epoch 210, Val Loss: 1.53119
Epoch 211, Val Loss: 1.53513
Epoch 212, Val Loss: 1.53183
Epoch 213, Val Loss: 1.53385
Epoch 214, Val Loss: 1.52959
Epoch 215, Val Loss: 1.52978
Epoch 216, Val Loss: 1.53534
Epoch 217, Val Loss: 1.53036
Epoch 218, Val Loss: 1.53422
Epoch 219, Val Loss: 1.52904
Epoch 220, Val Loss: 1.52883
Epoch 221, Val Loss: 1.53187
Epoch 222, Val Loss: 1.52811
Epoch 223, Val Loss: 1.52919
Epoch 224, Val Loss: 1.53237
Epoch 225, Val Loss: 1.53126
Epoch 226, Val Loss: 1.53182
Epoch 227, Val Loss: 1.53468
Epoch 228, Val Loss: 1.53408
Epoch 229, Val Loss: 1.53348
Epoch 230, Val Loss: 1.52743
Epoch 231, Val Loss: 1.53139
Epoch 232, Val Loss: 1.52644
Epoch 233, Val Loss: 1.52833
Epoch 234, Val Loss: 1.52736
Epoch 235, Val Loss: 1.52669
Epoch 236, Val Loss: 1.53182
Epoch 237, Val Loss: 1.52972
Epoch 238, Val Loss: 1.53112
Epoch 239, Val Loss: 1.52999
Epoch 240, Val Loss: 1.52868
Epoch 241, Val Loss: 1.53083
Epoch 242, Val Loss: 1.52690
Epoch 243, Val Loss: 1.53121
Epoch 244, Val Loss: 1.52611
Epoch 245, Val Loss: 1.53110
Epoch 246, Val Loss: 1.52635
Epoch 247, Val Loss: 1.52710
Epoch 248, Val Loss: 1.53313
Epoch 249, Val Loss: 1.53166
Epoch 250, Val Loss: 1.53604
Epoch 251, Val Loss: 1.52715
Epoch 252, Val Loss: 1.53039
Epoch 253, Val Loss: 1.52576
Epoch 254, Val Loss: 1.52756
Epoch 255, Val Loss: 1.52733
Epoch 256, Val Loss: 1.52651
Epoch 257, Val Loss: 1.53154
Epoch 258, Val Loss: 1.52832
Epoch 259, Val Loss: 1.53169
Epoch 260, Val Loss: 1.52540
Epoch 261, Val Loss: 1.52653
Epoch 262, Val Loss: 1.52414
Epoch 263, Val Loss: 1.52433
Epoch 264, Val Loss: 1.52721
Epoch 265, Val Loss: 1.52540
Epoch 266, Val Loss: 1.53006
Epoch 267, Val Loss: 1.52581
Epoch 268, Val Loss: 1.52756
Epoch 269, Val Loss: 1.52344
Epoch 270, Val Loss: 1.52427
Epoch 271, Val Loss: 1.52600
Epoch 272, Val Loss: 1.52477
Epoch 273, Val Loss: 1.52875
Epoch 274, Val Loss: 1.52492
Epoch 275, Val Loss: 1.52717
Epoch 276, Val Loss: 1.52282
Epoch 277, Val Loss: 1.52379
Epoch 278, Val Loss: 1.52389
Epoch 279, Val Loss: 1.52528
Epoch 280, Val Loss: 1.52713
Epoch 281, Val Loss: 1.52404
Epoch 282, Val Loss: 1.52793
Epoch 283, Val Loss: 1.52273
Epoch 284, Val Loss: 1.52508
Epoch 285, Val Loss: 1.52221
Epoch 286, Val Loss: 1.52526
Epoch 287, Val Loss: 1.53065
Epoch 288, Val Loss: 1.52608
Epoch 289, Val Loss: 1.52714
Epoch 290, Val Loss: 1.52263
Epoch 291, Val Loss: 1.52370
Epoch 292, Val Loss: 1.52129
Epoch 293, Val Loss: 1.52263
Epoch 294, Val Loss: 1.52328
Epoch 295, Val Loss: 1.52376
Epoch 296, Val Loss: 1.52436
Epoch 297, Val Loss: 1.52292
Epoch 298, Val Loss: 1.52301
Epoch 299, Val Loss: 1.52320
Epoch 300, Val Loss: 1.52478
Epoch 301, Val Loss: 1.52478
Epoch 302, Val Loss: 1.52414
Epoch 303, Val Loss: 1.52796
Epoch 304, Val Loss: 1.52448
Epoch 305, Val Loss: 1.53031
Epoch 306, Val Loss: 1.52214
Epoch 307, Val Loss: 1.52251
Epoch 308, Val Loss: 1.52459
Epoch 309, Val Loss: 1.52239
Epoch 310, Val Loss: 1.52628
Epoch 311, Val Loss: 1.52045
Epoch 312, Val Loss: 1.51972
Epoch 313, Val Loss: 1.51926
Epoch 314, Val Loss: 1.51992
Epoch 315, Val Loss: 1.52075
Epoch 316, Val Loss: 1.52062
Epoch 317, Val Loss: 1.52530
Epoch 318, Val Loss: 1.52228
Epoch 319, Val Loss: 1.52288
Epoch 320, Val Loss: 1.52083
Epoch 321, Val Loss: 1.51951
Epoch 322, Val Loss: 1.52010
Epoch 323, Val Loss: 1.52621
Epoch 324, Val Loss: 1.52613
Epoch 325, Val Loss: 1.52432
Epoch 326, Val Loss: 1.52867
Epoch 327, Val Loss: 1.52467
Epoch 328, Val Loss: 1.52310
Epoch 329, Val Loss: 1.52337
Epoch 330, Val Loss: 1.52347
Epoch 331, Val Loss: 1.52240
Epoch 332, Val Loss: 1.52328
Epoch 333, Val Loss: 1.52233
Epoch 334, Val Loss: 1.52274
Epoch 335, Val Loss: 1.52493
Epoch 336, Val Loss: 1.52366
Epoch 337, Val Loss: 1.52395
Epoch 338, Val Loss: 1.52017
Epoch 339, Val Loss: 1.51903
Epoch 340, Val Loss: 1.51858
Epoch 341, Val Loss: 1.51920
Epoch 342, Val Loss: 1.52219
Epoch 343, Val Loss: 1.51910
Epoch 344, Val Loss: 1.51883
Epoch 345, Val Loss: 1.51759
Epoch 346, Val Loss: 1.51679
Epoch 347, Val Loss: 1.51832
Epoch 348, Val Loss: 1.51887
Epoch 349, Val Loss: 1.52039
Epoch 350, Val Loss: 1.51906
Epoch 351, Val Loss: 1.52157
Epoch 352, Val Loss: 1.51795
Epoch 353, Val Loss: 1.51648
Epoch 354, Val Loss: 1.51623
Epoch 355, Val Loss: 1.51632
Epoch 356, Val Loss: 1.51575
Epoch 357, Val Loss: 1.51607
Epoch 358, Val Loss: 1.51744
Epoch 359, Val Loss: 1.51883
Epoch 360, Val Loss: 1.52117
Epoch 361, Val Loss: 1.51922
Epoch 362, Val Loss: 1.51797
Epoch 363, Val Loss: 1.51754
Epoch 364, Val Loss: 1.51821
Epoch 365, Val Loss: 1.51923
Epoch 366, Val Loss: 1.52122
Epoch 367, Val Loss: 1.52031
Epoch 368, Val Loss: 1.52035
Epoch 369, Val Loss: 1.52172
Epoch 370, Val Loss: 1.51635
Epoch 371, Val Loss: 1.51945
Epoch 372, Val Loss: 1.52006
Epoch 373, Val Loss: 1.51926
Epoch 374, Val Loss: 1.51490
Epoch 375, Val Loss: 1.52183
Epoch 376, Val Loss: 1.51791
Epoch 377, Val Loss: 1.51756
Epoch 378, Val Loss: 1.52204
Epoch 379, Val Loss: 1.52084
Epoch 380, Val Loss: 1.51969
Epoch 381, Val Loss: 1.51897
Epoch 382, Val Loss: 1.51754
Epoch 383, Val Loss: 1.51775
Epoch 384, Val Loss: 1.51899
Epoch 385, Val Loss: 1.51675
Epoch 386, Val Loss: 1.51605
Epoch 387, Val Loss: 1.51668
Epoch 388, Val Loss: 1.51541
Epoch 389, Val Loss: 1.51736
Epoch 390, Val Loss: 1.51597
Epoch 391, Val Loss: 1.51393
Epoch 392, Val Loss: 1.51642
Epoch 393, Val Loss: 1.52269
Epoch 394, Val Loss: 1.52972
Epoch 395, Val Loss: 1.52246
Epoch 396, Val Loss: 1.52057
Epoch 397, Val Loss: 1.51589
Epoch 398, Val Loss: 1.52104
Epoch 399, Val Loss: 1.51411
{'Log Loss - mean': 3.8480992012334583, 'Log Loss - std': 0.0, 'AUC - mean': 0.48833209909789493, 'AUC - std': 0.0, 'Accuracy - mean': 0.731323631920002, 'Accuracy - std': 0.0, 'F1 score - mean': 0.6779832886221615, 'F1 score - std': 0.0}
On Device: cuda
Epoch 0, Val Loss: 1.80757
Epoch 1, Val Loss: 1.71627
Epoch 2, Val Loss: 1.69817
Epoch 3, Val Loss: 1.67893
Epoch 4, Val Loss: 1.64324
Epoch 5, Val Loss: 1.61613
Epoch 6, Val Loss: 1.59849
Epoch 7, Val Loss: 1.58941
Epoch 8, Val Loss: 1.56520
Epoch 9, Val Loss: 1.50517
Epoch 10, Val Loss: 1.47417
Epoch 11, Val Loss: 1.46772
Epoch 12, Val Loss: 1.46492
Epoch 13, Val Loss: 1.46239
Epoch 14, Val Loss: 1.46157
Epoch 15, Val Loss: 1.46067
Epoch 16, Val Loss: 1.45878
Epoch 17, Val Loss: 1.45868
Epoch 18, Val Loss: 1.45800
Epoch 19, Val Loss: 1.45661
Epoch 20, Val Loss: 1.45544
Epoch 21, Val Loss: 1.45727
Epoch 22, Val Loss: 1.45383
Epoch 23, Val Loss: 1.45321
Epoch 24, Val Loss: 1.45257
Epoch 25, Val Loss: 1.45116
Epoch 26, Val Loss: 1.45125
Epoch 27, Val Loss: 1.45086
Epoch 28, Val Loss: 1.44933
Epoch 29, Val Loss: 1.44977
Epoch 30, Val Loss: 1.44813
Epoch 31, Val Loss: 1.44935
Epoch 32, Val Loss: 1.44726
Epoch 33, Val Loss: 1.44944
Epoch 34, Val Loss: 1.44627
Epoch 35, Val Loss: 1.44745
Epoch 36, Val Loss: 1.44547
Epoch 37, Val Loss: 1.44694
Epoch 38, Val Loss: 1.44431
Epoch 39, Val Loss: 1.44598
Epoch 40, Val Loss: 1.44375
Epoch 41, Val Loss: 1.44569
Epoch 42, Val Loss: 1.44290
Epoch 43, Val Loss: 1.44443
Epoch 44, Val Loss: 1.44232
Epoch 45, Val Loss: 1.44389
Epoch 46, Val Loss: 1.44155
Epoch 47, Val Loss: 1.44273
Epoch 48, Val Loss: 1.44115
Epoch 49, Val Loss: 1.44204
Epoch 50, Val Loss: 1.44042
Epoch 51, Val Loss: 1.44144
Epoch 52, Val Loss: 1.43960
Epoch 53, Val Loss: 1.44052
Epoch 54, Val Loss: 1.43929
Epoch 55, Val Loss: 1.43992
Epoch 56, Val Loss: 1.43896
Epoch 57, Val Loss: 1.43937
Epoch 58, Val Loss: 1.43849
Epoch 59, Val Loss: 1.43869
Epoch 60, Val Loss: 1.43786
Epoch 61, Val Loss: 1.43817
Epoch 62, Val Loss: 1.43753
Epoch 63, Val Loss: 1.43791
Epoch 64, Val Loss: 1.43669
Epoch 65, Val Loss: 1.43788
Epoch 66, Val Loss: 1.43617
Epoch 67, Val Loss: 1.43723
Epoch 68, Val Loss: 1.43600
Epoch 69, Val Loss: 1.43741
Epoch 70, Val Loss: 1.43549
Epoch 71, Val Loss: 1.43688
Epoch 72, Val Loss: 1.43524
Epoch 73, Val Loss: 1.43656
Epoch 74, Val Loss: 1.43495
Epoch 75, Val Loss: 1.43627
Epoch 76, Val Loss: 1.43447
Epoch 77, Val Loss: 1.43701
Epoch 78, Val Loss: 1.43385
Epoch 79, Val Loss: 1.43660
Epoch 80, Val Loss: 1.43437
Epoch 81, Val Loss: 1.43556
Epoch 82, Val Loss: 1.43373
Epoch 83, Val Loss: 1.43543
Epoch 84, Val Loss: 1.43280
Epoch 85, Val Loss: 1.43423
Epoch 86, Val Loss: 1.43288
Epoch 87, Val Loss: 1.43394
Epoch 88, Val Loss: 1.43323
Epoch 89, Val Loss: 1.43408
Epoch 90, Val Loss: 1.43264
Epoch 91, Val Loss: 1.43317
Epoch 92, Val Loss: 1.43226
Epoch 93, Val Loss: 1.43258
Epoch 94, Val Loss: 1.43243
Epoch 95, Val Loss: 1.43294
Epoch 96, Val Loss: 1.43299
Epoch 97, Val Loss: 1.43261
Epoch 98, Val Loss: 1.43171
Epoch 99, Val Loss: 1.43137
Epoch 100, Val Loss: 1.43064
Epoch 101, Val Loss: 1.43054
Epoch 102, Val Loss: 1.43075
Epoch 103, Val Loss: 1.43034
Epoch 104, Val Loss: 1.43097
Epoch 105, Val Loss: 1.43116
Epoch 106, Val Loss: 1.43132
Epoch 107, Val Loss: 1.43143
Epoch 108, Val Loss: 1.43106
Epoch 109, Val Loss: 1.42918
Epoch 110, Val Loss: 1.42869
Epoch 111, Val Loss: 1.42933
Epoch 112, Val Loss: 1.42957
Epoch 113, Val Loss: 1.43030
Epoch 114, Val Loss: 1.43155
Epoch 115, Val Loss: 1.43224
Epoch 116, Val Loss: 1.43448
Epoch 117, Val Loss: 1.43263
Epoch 118, Val Loss: 1.43387
Epoch 119, Val Loss: 1.42965
Epoch 120, Val Loss: 1.43130
Epoch 121, Val Loss: 1.43198
Epoch 122, Val Loss: 1.43043
Epoch 123, Val Loss: 1.42931
Epoch 124, Val Loss: 1.43031
Epoch 125, Val Loss: 1.42773
Epoch 126, Val Loss: 1.42716
Epoch 127, Val Loss: 1.42789
Epoch 128, Val Loss: 1.42914
Epoch 129, Val Loss: 1.42767
Epoch 130, Val Loss: 1.43136
Epoch 131, Val Loss: 1.43244
Epoch 132, Val Loss: 1.42996
Epoch 133, Val Loss: 1.43358
Epoch 134, Val Loss: 1.42865
Epoch 135, Val Loss: 1.42836
Epoch 136, Val Loss: 1.43456
Epoch 137, Val Loss: 1.43384
Epoch 138, Val Loss: 1.42776
Epoch 139, Val Loss: 1.43354
Epoch 140, Val Loss: 1.43071
Epoch 141, Val Loss: 1.42757
Epoch 142, Val Loss: 1.43153
Epoch 143, Val Loss: 1.42814
Epoch 144, Val Loss: 1.42823
Epoch 145, Val Loss: 1.42926
Epoch 146, Val Loss: 1.42773
Epoch 147, Val Loss: 1.42788
Epoch 148, Val Loss: 1.43040
Epoch 149, Val Loss: 1.42911
Epoch 150, Val Loss: 1.42706
Epoch 151, Val Loss: 1.42913
Epoch 152, Val Loss: 1.42577
Epoch 153, Val Loss: 1.42752
Epoch 154, Val Loss: 1.42796
Epoch 155, Val Loss: 1.42928
Epoch 156, Val Loss: 1.42733
Epoch 157, Val Loss: 1.42845
Epoch 158, Val Loss: 1.42609
Epoch 159, Val Loss: 1.42631
Epoch 160, Val Loss: 1.42636
Epoch 161, Val Loss: 1.42803
Epoch 162, Val Loss: 1.42774
Epoch 163, Val Loss: 1.42753
Epoch 164, Val Loss: 1.42579
Epoch 165, Val Loss: 1.42390
Epoch 166, Val Loss: 1.42113
Epoch 167, Val Loss: 1.42719
Epoch 168, Val Loss: 1.42707
Epoch 169, Val Loss: 1.42720
Epoch 170, Val Loss: 1.42504
Epoch 171, Val Loss: 1.42390
Epoch 172, Val Loss: 1.42218
Epoch 173, Val Loss: 1.42203
Epoch 174, Val Loss: 1.42452
Epoch 175, Val Loss: 1.42065
Epoch 176, Val Loss: 1.42006
Epoch 177, Val Loss: 1.42019
Epoch 178, Val Loss: 1.42277
Epoch 179, Val Loss: 1.42291
Epoch 180, Val Loss: 1.41978
Epoch 181, Val Loss: 1.41771
Epoch 182, Val Loss: 1.41774
Epoch 183, Val Loss: 1.41783
Epoch 184, Val Loss: 1.41794
Epoch 185, Val Loss: 1.41822
Epoch 186, Val Loss: 1.41809
Epoch 187, Val Loss: 1.41794
Epoch 188, Val Loss: 1.41872
Epoch 189, Val Loss: 1.42102
Epoch 190, Val Loss: 1.41845
Epoch 191, Val Loss: 1.41710
Epoch 192, Val Loss: 1.41849
Epoch 193, Val Loss: 1.41588
Epoch 194, Val Loss: 1.41701
Epoch 195, Val Loss: 1.42007
Epoch 196, Val Loss: 1.41689
Epoch 197, Val Loss: 1.41583
Epoch 198, Val Loss: 1.41704
Epoch 199, Val Loss: 1.41673
Epoch 200, Val Loss: 1.41787
Epoch 201, Val Loss: 1.41835
Epoch 202, Val Loss: 1.41632
Epoch 203, Val Loss: 1.41573
Epoch 204, Val Loss: 1.41606
Epoch 205, Val Loss: 1.41899
Epoch 206, Val Loss: 1.41701
Epoch 207, Val Loss: 1.41579
Epoch 208, Val Loss: 1.41697
Epoch 209, Val Loss: 1.41755
Epoch 210, Val Loss: 1.41669
Epoch 211, Val Loss: 1.42017
Epoch 212, Val Loss: 1.41568
Epoch 213, Val Loss: 1.41429
Epoch 214, Val Loss: 1.41501
Epoch 215, Val Loss: 1.41702
Epoch 216, Val Loss: 1.41694
Epoch 217, Val Loss: 1.41713
Epoch 218, Val Loss: 1.41636
Epoch 219, Val Loss: 1.41645
Epoch 220, Val Loss: 1.41702
Epoch 221, Val Loss: 1.41695
Epoch 222, Val Loss: 1.41588
Epoch 223, Val Loss: 1.41755
Epoch 224, Val Loss: 1.41614
Epoch 225, Val Loss: 1.41600
Epoch 226, Val Loss: 1.42068
Epoch 227, Val Loss: 1.41528
Epoch 228, Val Loss: 1.41396
Epoch 229, Val Loss: 1.41724
Epoch 230, Val Loss: 1.41664
Epoch 231, Val Loss: 1.41611
Epoch 232, Val Loss: 1.41472
Epoch 233, Val Loss: 1.41566
Epoch 234, Val Loss: 1.41674
Epoch 235, Val Loss: 1.41438
Epoch 236, Val Loss: 1.41245
Epoch 237, Val Loss: 1.41611
Epoch 238, Val Loss: 1.41547
Epoch 239, Val Loss: 1.41337
Epoch 240, Val Loss: 1.41679
Epoch 241, Val Loss: 1.41570
Epoch 242, Val Loss: 1.41292
Epoch 243, Val Loss: 1.41631
Epoch 244, Val Loss: 1.41456
Epoch 245, Val Loss: 1.41595
Epoch 246, Val Loss: 1.41271
Epoch 247, Val Loss: 1.41518
Epoch 248, Val Loss: 1.42029
Epoch 249, Val Loss: 1.41511
Epoch 250, Val Loss: 1.41410
Epoch 251, Val Loss: 1.41790
Epoch 252, Val Loss: 1.41620
Epoch 253, Val Loss: 1.41221
Epoch 254, Val Loss: 1.41583
Epoch 255, Val Loss: 1.41531
Epoch 256, Val Loss: 1.41773
Epoch 257, Val Loss: 1.41251
Epoch 258, Val Loss: 1.41378
Epoch 259, Val Loss: 1.41154
Epoch 260, Val Loss: 1.41212
Epoch 261, Val Loss: 1.41088
Epoch 262, Val Loss: 1.41297
Epoch 263, Val Loss: 1.41355
Epoch 264, Val Loss: 1.41616
Epoch 265, Val Loss: 1.41079
Epoch 266, Val Loss: 1.41192
Epoch 267, Val Loss: 1.40955
Epoch 268, Val Loss: 1.41231
Epoch 269, Val Loss: 1.40986
Epoch 270, Val Loss: 1.41520
Epoch 271, Val Loss: 1.41021
Epoch 272, Val Loss: 1.41149
Epoch 273, Val Loss: 1.40962
Epoch 274, Val Loss: 1.41219
Epoch 275, Val Loss: 1.41024
Epoch 276, Val Loss: 1.41326
Epoch 277, Val Loss: 1.40976
Epoch 278, Val Loss: 1.41526
Epoch 279, Val Loss: 1.40991
Epoch 280, Val Loss: 1.41115
Epoch 281, Val Loss: 1.40980
Epoch 282, Val Loss: 1.41260
Epoch 283, Val Loss: 1.40975
Epoch 284, Val Loss: 1.41250
Epoch 285, Val Loss: 1.40919
Epoch 286, Val Loss: 1.41063
Epoch 287, Val Loss: 1.40982
Epoch 288, Val Loss: 1.41317
Epoch 289, Val Loss: 1.41111
Epoch 290, Val Loss: 1.41340
Epoch 291, Val Loss: 1.40998
Epoch 292, Val Loss: 1.41210
Epoch 293, Val Loss: 1.41065
Epoch 294, Val Loss: 1.41240
Epoch 295, Val Loss: 1.41007
Epoch 296, Val Loss: 1.41200
Epoch 297, Val Loss: 1.41002
Epoch 298, Val Loss: 1.41047
Epoch 299, Val Loss: 1.40918
Epoch 300, Val Loss: 1.41200
Epoch 301, Val Loss: 1.41064
Epoch 302, Val Loss: 1.41156
Epoch 303, Val Loss: 1.41224
Epoch 304, Val Loss: 1.41157
Epoch 305, Val Loss: 1.40836
Epoch 306, Val Loss: 1.41336
Epoch 307, Val Loss: 1.40847
Epoch 308, Val Loss: 1.40915
Epoch 309, Val Loss: 1.40956
Epoch 310, Val Loss: 1.41116
Epoch 311, Val Loss: 1.40787
Epoch 312, Val Loss: 1.41105
Epoch 313, Val Loss: 1.40751
Epoch 314, Val Loss: 1.40861
Epoch 315, Val Loss: 1.41091
Epoch 316, Val Loss: 1.40935
Epoch 317, Val Loss: 1.40633
Epoch 318, Val Loss: 1.41151
Epoch 319, Val Loss: 1.40702
Epoch 320, Val Loss: 1.40672
Epoch 321, Val Loss: 1.40772
Epoch 322, Val Loss: 1.40781
Epoch 323, Val Loss: 1.40445
Epoch 324, Val Loss: 1.41137
Epoch 325, Val Loss: 1.40713
Epoch 326, Val Loss: 1.40790
Epoch 327, Val Loss: 1.40962
Epoch 328, Val Loss: 1.41128
Epoch 329, Val Loss: 1.40893
Epoch 330, Val Loss: 1.41303
Epoch 331, Val Loss: 1.41166
Epoch 332, Val Loss: 1.41267
Epoch 333, Val Loss: 1.40724
Epoch 334, Val Loss: 1.40457
Epoch 335, Val Loss: 1.40634
Epoch 336, Val Loss: 1.40719
Epoch 337, Val Loss: 1.40639
Epoch 338, Val Loss: 1.41713
Epoch 339, Val Loss: 1.40735
Epoch 340, Val Loss: 1.41036
Epoch 341, Val Loss: 1.40405
Epoch 342, Val Loss: 1.40714
Epoch 343, Val Loss: 1.40521
Epoch 344, Val Loss: 1.40601
Epoch 345, Val Loss: 1.40454
Epoch 346, Val Loss: 1.40589
Epoch 347, Val Loss: 1.40906
Epoch 348, Val Loss: 1.41735
Epoch 349, Val Loss: 1.40880
Epoch 350, Val Loss: 1.40722
Epoch 351, Val Loss: 1.40276
Epoch 352, Val Loss: 1.40836
Epoch 353, Val Loss: 1.40935
Epoch 354, Val Loss: 1.40743
Epoch 355, Val Loss: 1.40735
Epoch 356, Val Loss: 1.40571
Epoch 357, Val Loss: 1.40308
Epoch 358, Val Loss: 1.40293
Epoch 359, Val Loss: 1.40247
Epoch 360, Val Loss: 1.40232
Epoch 361, Val Loss: 1.40334
Epoch 362, Val Loss: 1.40836
Epoch 363, Val Loss: 1.40541
Epoch 364, Val Loss: 1.40646
Epoch 365, Val Loss: 1.40389
Epoch 366, Val Loss: 1.40338
Epoch 367, Val Loss: 1.40284
Epoch 368, Val Loss: 1.40115
Epoch 369, Val Loss: 1.40305
Epoch 370, Val Loss: 1.40613
Epoch 371, Val Loss: 1.40476
Epoch 372, Val Loss: 1.40321
Epoch 373, Val Loss: 1.40317
Epoch 374, Val Loss: 1.40624
Epoch 375, Val Loss: 1.40313
Epoch 376, Val Loss: 1.40877
Epoch 377, Val Loss: 1.40604
Epoch 378, Val Loss: 1.40501
Epoch 379, Val Loss: 1.40346
Epoch 380, Val Loss: 1.40438
Epoch 381, Val Loss: 1.40370
Epoch 382, Val Loss: 1.40583
Epoch 383, Val Loss: 1.41059
Epoch 384, Val Loss: 1.41615
Epoch 385, Val Loss: 1.40852
Epoch 386, Val Loss: 1.40969
Epoch 387, Val Loss: 1.40608
Epoch 388, Val Loss: 1.40250
Epoch 389, Val Loss: 1.40096
Epoch 390, Val Loss: 1.40093
Epoch 391, Val Loss: 1.40086
Epoch 392, Val Loss: 1.40533
Epoch 393, Val Loss: 1.40167
Epoch 394, Val Loss: 1.40226
Epoch 395, Val Loss: 1.40044
Epoch 396, Val Loss: 1.40020
Epoch 397, Val Loss: 1.40037
Epoch 398, Val Loss: 1.40230
Epoch 399, Val Loss: 1.40277
{'Log Loss - mean': 3.5385653472780927, 'Log Loss - std': 0.3095338539553658, 'AUC - mean': 0.5395236085784925, 'AUC - std': 0.0511915094805975, 'Accuracy - mean': 0.750927256611275, 'Accuracy - std': 0.019603624691273025, 'F1 score - mean': 0.7073491093629611, 'F1 score - std': 0.02936582074079963}
On Device: cuda
Epoch 0, Val Loss: 1.80904
Epoch 1, Val Loss: 1.72333
Epoch 2, Val Loss: 1.69984
Epoch 3, Val Loss: 1.67657
Epoch 4, Val Loss: 1.63919
Epoch 5, Val Loss: 1.61680
Epoch 6, Val Loss: 1.60188
Epoch 7, Val Loss: 1.59244
Epoch 8, Val Loss: 1.57983
Epoch 9, Val Loss: 1.57529
Epoch 10, Val Loss: 1.57241
Epoch 11, Val Loss: 1.57142
Epoch 12, Val Loss: 1.56605
Epoch 13, Val Loss: 1.56601
Epoch 14, Val Loss: 1.56528
Epoch 15, Val Loss: 1.56280
Epoch 16, Val Loss: 1.56271
Epoch 17, Val Loss: 1.56208
Epoch 18, Val Loss: 1.56043
Epoch 19, Val Loss: 1.56054
Epoch 20, Val Loss: 1.56001
Epoch 21, Val Loss: 1.55868
Epoch 22, Val Loss: 1.55871
Epoch 23, Val Loss: 1.55818
Epoch 24, Val Loss: 1.55723
Epoch 25, Val Loss: 1.55714
Epoch 26, Val Loss: 1.55668
Epoch 27, Val Loss: 1.55594
Epoch 28, Val Loss: 1.55573
Epoch 29, Val Loss: 1.55525
Epoch 30, Val Loss: 1.55462
Epoch 31, Val Loss: 1.55429
Epoch 32, Val Loss: 1.55384
Epoch 33, Val Loss: 1.55327
Epoch 34, Val Loss: 1.55274
Epoch 35, Val Loss: 1.55216
Epoch 36, Val Loss: 1.55115
Epoch 37, Val Loss: 1.55015
Epoch 38, Val Loss: 1.54956
Epoch 39, Val Loss: 1.54925
Epoch 40, Val Loss: 1.54880
Epoch 41, Val Loss: 1.54867
Epoch 42, Val Loss: 1.54811
Epoch 43, Val Loss: 1.54831
Epoch 44, Val Loss: 1.54769
Epoch 45, Val Loss: 1.54782
Epoch 46, Val Loss: 1.54743
Epoch 47, Val Loss: 1.54759
Epoch 48, Val Loss: 1.54690
Epoch 49, Val Loss: 1.54717
Epoch 50, Val Loss: 1.54608
Epoch 51, Val Loss: 1.54597
Epoch 52, Val Loss: 1.54595
Epoch 53, Val Loss: 1.54587
Epoch 54, Val Loss: 1.54514
Epoch 55, Val Loss: 1.54488
Epoch 56, Val Loss: 1.54506
Epoch 57, Val Loss: 1.54475
Epoch 58, Val Loss: 1.54438
Epoch 59, Val Loss: 1.54378
Epoch 60, Val Loss: 1.54440
Epoch 61, Val Loss: 1.54376
Epoch 62, Val Loss: 1.54395
Epoch 63, Val Loss: 1.54339
Epoch 64, Val Loss: 1.54386
Epoch 65, Val Loss: 1.54343
Epoch 66, Val Loss: 1.54395
Epoch 67, Val Loss: 1.54300
Epoch 68, Val Loss: 1.54408
Epoch 69, Val Loss: 1.54308
Epoch 70, Val Loss: 1.54461
Epoch 71, Val Loss: 1.54294
Epoch 72, Val Loss: 1.54388
Epoch 73, Val Loss: 1.54250
Epoch 74, Val Loss: 1.54365
Epoch 75, Val Loss: 1.54179
Epoch 76, Val Loss: 1.54356
Epoch 77, Val Loss: 1.54168
Epoch 78, Val Loss: 1.54266
Epoch 79, Val Loss: 1.54066
Epoch 80, Val Loss: 1.54251
Epoch 81, Val Loss: 1.54050
Epoch 82, Val Loss: 1.54245
Epoch 83, Val Loss: 1.54041
Epoch 84, Val Loss: 1.54165
Epoch 85, Val Loss: 1.53963
Epoch 86, Val Loss: 1.54152
Epoch 87, Val Loss: 1.53963
Epoch 88, Val Loss: 1.54159
Epoch 89, Val Loss: 1.53954
Epoch 90, Val Loss: 1.54137
Epoch 91, Val Loss: 1.53887
Epoch 92, Val Loss: 1.54058
Epoch 93, Val Loss: 1.53911
Epoch 94, Val Loss: 1.54185
Epoch 95, Val Loss: 1.53912
Epoch 96, Val Loss: 1.54071
Epoch 97, Val Loss: 1.53946
Epoch 98, Val Loss: 1.53983
Epoch 99, Val Loss: 1.53884
Epoch 100, Val Loss: 1.53871
Epoch 101, Val Loss: 1.53840
Epoch 102, Val Loss: 1.54089
Epoch 103, Val Loss: 1.53971
Epoch 104, Val Loss: 1.53999
Epoch 105, Val Loss: 1.54146
Epoch 106, Val Loss: 1.53926
Epoch 107, Val Loss: 1.53999
Epoch 108, Val Loss: 1.53946
Epoch 109, Val Loss: 1.53962
Epoch 110, Val Loss: 1.53870
Epoch 111, Val Loss: 1.53753
Epoch 112, Val Loss: 1.53933
Epoch 113, Val Loss: 1.53776
Epoch 114, Val Loss: 1.53743
Epoch 115, Val Loss: 1.53683
Epoch 116, Val Loss: 1.53748
Epoch 117, Val Loss: 1.53751
Epoch 118, Val Loss: 1.53880
Epoch 119, Val Loss: 1.54088
Epoch 120, Val Loss: 1.53809
Epoch 121, Val Loss: 1.53828
Epoch 122, Val Loss: 1.53758
Epoch 123, Val Loss: 1.53580
Epoch 124, Val Loss: 1.53567
Epoch 125, Val Loss: 1.53627
Epoch 126, Val Loss: 1.53698
Epoch 127, Val Loss: 1.53872
Epoch 128, Val Loss: 1.53759
Epoch 129, Val Loss: 1.53970
Epoch 130, Val Loss: 1.53694
Epoch 131, Val Loss: 1.53484
Epoch 132, Val Loss: 1.53655
Epoch 133, Val Loss: 1.53587
Epoch 134, Val Loss: 1.53663
Epoch 135, Val Loss: 1.53542
Epoch 136, Val Loss: 1.53825
Epoch 137, Val Loss: 1.54073
Epoch 138, Val Loss: 1.53583
Epoch 139, Val Loss: 1.53838
Epoch 140, Val Loss: 1.53543
Epoch 141, Val Loss: 1.53570
Epoch 142, Val Loss: 1.53551
Epoch 143, Val Loss: 1.53811
Epoch 144, Val Loss: 1.53864
Epoch 145, Val Loss: 1.53616
Epoch 146, Val Loss: 1.54354
Epoch 147, Val Loss: 1.55022
Epoch 148, Val Loss: 1.54183
Epoch 149, Val Loss: 1.54051
Epoch 150, Val Loss: 1.53748
Epoch 151, Val Loss: 1.53735
Epoch 152, Val Loss: 1.53541
Epoch 153, Val Loss: 1.53599
Epoch 154, Val Loss: 1.53452
Epoch 155, Val Loss: 1.53669
Epoch 156, Val Loss: 1.53543
Epoch 157, Val Loss: 1.53284
Epoch 158, Val Loss: 1.53533
Epoch 159, Val Loss: 1.53635
Epoch 160, Val Loss: 1.53392
Epoch 161, Val Loss: 1.53717
Epoch 162, Val Loss: 1.53609
Epoch 163, Val Loss: 1.53357
Epoch 164, Val Loss: 1.53721
Epoch 165, Val Loss: 1.54061
Epoch 166, Val Loss: 1.53596
Epoch 167, Val Loss: 1.53441
Epoch 168, Val Loss: 1.53467
Epoch 169, Val Loss: 1.53289
Epoch 170, Val Loss: 1.53420
Epoch 171, Val Loss: 1.53409
Epoch 172, Val Loss: 1.53314
Epoch 173, Val Loss: 1.53416
Epoch 174, Val Loss: 1.53337
Epoch 175, Val Loss: 1.53217
Epoch 176, Val Loss: 1.53400
Epoch 177, Val Loss: 1.53542
Epoch 178, Val Loss: 1.53296
Epoch 179, Val Loss: 1.53714
Epoch 180, Val Loss: 1.53825
Epoch 181, Val Loss: 1.53574
Epoch 182, Val Loss: 1.53341
Epoch 183, Val Loss: 1.53437
Epoch 184, Val Loss: 1.53391
Epoch 185, Val Loss: 1.53596
Epoch 186, Val Loss: 1.53230
Epoch 187, Val Loss: 1.53422
Epoch 188, Val Loss: 1.53119
Epoch 189, Val Loss: 1.53038
Epoch 190, Val Loss: 1.53601
Epoch 191, Val Loss: 1.53227
Epoch 192, Val Loss: 1.53144
Epoch 193, Val Loss: 1.53070
Epoch 194, Val Loss: 1.53077
Epoch 195, Val Loss: 1.53240
Epoch 196, Val Loss: 1.53150
Epoch 197, Val Loss: 1.53301
Epoch 198, Val Loss: 1.52975
Epoch 199, Val Loss: 1.52987
Epoch 200, Val Loss: 1.53400
Epoch 201, Val Loss: 1.53489
Epoch 202, Val Loss: 1.53149
Epoch 203, Val Loss: 1.53227
Epoch 204, Val Loss: 1.53272
Epoch 205, Val Loss: 1.53284
Epoch 206, Val Loss: 1.54069
Epoch 207, Val Loss: 1.53420
Epoch 208, Val Loss: 1.53081
Epoch 209, Val Loss: 1.53076
Epoch 210, Val Loss: 1.53167
Epoch 211, Val Loss: 1.53078
Epoch 212, Val Loss: 1.53572
Epoch 213, Val Loss: 1.53127
Epoch 214, Val Loss: 1.53045
Epoch 215, Val Loss: 1.52935
Epoch 216, Val Loss: 1.52995
Epoch 217, Val Loss: 1.52846
Epoch 218, Val Loss: 1.53187
Epoch 219, Val Loss: 1.53118
Epoch 220, Val Loss: 1.52988
Epoch 221, Val Loss: 1.52942
Epoch 222, Val Loss: 1.52987
Epoch 223, Val Loss: 1.52938
Epoch 224, Val Loss: 1.52980
Epoch 225, Val Loss: 1.53076
Epoch 226, Val Loss: 1.53039
Epoch 227, Val Loss: 1.52830
Epoch 228, Val Loss: 1.52925
Epoch 229, Val Loss: 1.52948
Epoch 230, Val Loss: 1.52899
Epoch 231, Val Loss: 1.53083
Epoch 232, Val Loss: 1.53006
Epoch 233, Val Loss: 1.52903
Epoch 234, Val Loss: 1.53639
Epoch 235, Val Loss: 1.53515
Epoch 236, Val Loss: 1.53030
Epoch 237, Val Loss: 1.53312
Epoch 238, Val Loss: 1.53460
Epoch 239, Val Loss: 1.53356
Epoch 240, Val Loss: 1.53609
Epoch 241, Val Loss: 1.52906
Epoch 242, Val Loss: 1.52966
Epoch 243, Val Loss: 1.52722
Epoch 244, Val Loss: 1.52755
Epoch 245, Val Loss: 1.52844
Epoch 246, Val Loss: 1.52994
Epoch 247, Val Loss: 1.52863
Epoch 248, Val Loss: 1.53040
Epoch 249, Val Loss: 1.53028
Epoch 250, Val Loss: 1.52713
Epoch 251, Val Loss: 1.53028
Epoch 252, Val Loss: 1.52884
Epoch 253, Val Loss: 1.52735
Epoch 254, Val Loss: 1.53490
Epoch 255, Val Loss: 1.53126
Epoch 256, Val Loss: 1.52853
Epoch 257, Val Loss: 1.52795
Epoch 258, Val Loss: 1.52713
Epoch 259, Val Loss: 1.52693
Epoch 260, Val Loss: 1.53092
Epoch 261, Val Loss: 1.52560
Epoch 262, Val Loss: 1.52783
Epoch 263, Val Loss: 1.52590
Epoch 264, Val Loss: 1.52647
Epoch 265, Val Loss: 1.52857
Epoch 266, Val Loss: 1.52971
Epoch 267, Val Loss: 1.52515
Epoch 268, Val Loss: 1.52909
Epoch 269, Val Loss: 1.52707
Epoch 270, Val Loss: 1.52864
Epoch 271, Val Loss: 1.53407
Epoch 272, Val Loss: 1.52998
Epoch 273, Val Loss: 1.52634
Epoch 274, Val Loss: 1.52549
Epoch 275, Val Loss: 1.52466
Epoch 276, Val Loss: 1.52390
Epoch 277, Val Loss: 1.52732
Epoch 278, Val Loss: 1.52615
Epoch 279, Val Loss: 1.52354
Epoch 280, Val Loss: 1.52557
Epoch 281, Val Loss: 1.52442
Epoch 282, Val Loss: 1.52386
Epoch 283, Val Loss: 1.52513
Epoch 284, Val Loss: 1.52585
Epoch 285, Val Loss: 1.52488
Epoch 286, Val Loss: 1.52554
Epoch 287, Val Loss: 1.52564
Epoch 288, Val Loss: 1.52470
Epoch 289, Val Loss: 1.52429
Epoch 290, Val Loss: 1.52368
Epoch 291, Val Loss: 1.52166
Epoch 292, Val Loss: 1.52345
Epoch 293, Val Loss: 1.52239
Epoch 294, Val Loss: 1.52252
Epoch 295, Val Loss: 1.52287
Epoch 296, Val Loss: 1.52429
Epoch 297, Val Loss: 1.52236
Epoch 298, Val Loss: 1.52285
Epoch 299, Val Loss: 1.52382
Epoch 300, Val Loss: 1.52204
Epoch 301, Val Loss: 1.52069
Epoch 302, Val Loss: 1.52237
Epoch 303, Val Loss: 1.52013
Epoch 304, Val Loss: 1.51908
Epoch 305, Val Loss: 1.52041
Epoch 306, Val Loss: 1.52120
Epoch 307, Val Loss: 1.52018
Epoch 308, Val Loss: 1.52143
Epoch 309, Val Loss: 1.52021
Epoch 310, Val Loss: 1.52123
Epoch 311, Val Loss: 1.51938
Epoch 312, Val Loss: 1.52328
Epoch 313, Val Loss: 1.52280
Epoch 314, Val Loss: 1.52053
Epoch 315, Val Loss: 1.52293
Epoch 316, Val Loss: 1.52327
Epoch 317, Val Loss: 1.52064
Epoch 318, Val Loss: 1.52030
Epoch 319, Val Loss: 1.52106
Epoch 320, Val Loss: 1.52371
Epoch 321, Val Loss: 1.52231
Epoch 322, Val Loss: 1.52245
Epoch 323, Val Loss: 1.51928
Epoch 324, Val Loss: 1.51879
Epoch 325, Val Loss: 1.51790
Epoch 326, Val Loss: 1.52187
Epoch 327, Val Loss: 1.51879
Epoch 328, Val Loss: 1.51929
Epoch 329, Val Loss: 1.51881
Epoch 330, Val Loss: 1.51621
Epoch 331, Val Loss: 1.51652
Epoch 332, Val Loss: 1.51929
Epoch 333, Val Loss: 1.51857
Epoch 334, Val Loss: 1.51993
Epoch 335, Val Loss: 1.52021
Epoch 336, Val Loss: 1.52262
Epoch 337, Val Loss: 1.52126
Epoch 338, Val Loss: 1.52221
Epoch 339, Val Loss: 1.52669
Epoch 340, Val Loss: 1.52241
Epoch 341, Val Loss: 1.51937
Epoch 342, Val Loss: 1.51878
Epoch 343, Val Loss: 1.51673
Epoch 344, Val Loss: 1.51606
Epoch 345, Val Loss: 1.51838
Epoch 346, Val Loss: 1.51907
Epoch 347, Val Loss: 1.51731
Epoch 348, Val Loss: 1.51562
Epoch 349, Val Loss: 1.51510
Epoch 350, Val Loss: 1.51553
Epoch 351, Val Loss: 1.51677
Epoch 352, Val Loss: 1.51677
Epoch 353, Val Loss: 1.51564
Epoch 354, Val Loss: 1.51690
Epoch 355, Val Loss: 1.51801
Epoch 356, Val Loss: 1.51658
Epoch 357, Val Loss: 1.51634
Epoch 358, Val Loss: 1.52121
Epoch 359, Val Loss: 1.52088
Epoch 360, Val Loss: 1.51693
Epoch 361, Val Loss: 1.52070
Epoch 362, Val Loss: 1.51923
Epoch 363, Val Loss: 1.52349
Epoch 364, Val Loss: 1.52565
Epoch 365, Val Loss: 1.52386
Epoch 366, Val Loss: 1.52382
Epoch 367, Val Loss: 1.51932
Epoch 368, Val Loss: 1.51983
Epoch 369, Val Loss: 1.51715
Epoch 370, Val Loss: 1.51881
Epoch 371, Val Loss: 1.51823
Epoch 372, Val Loss: 1.51844
Epoch 373, Val Loss: 1.52382
Epoch 374, Val Loss: 1.51785
Epoch 375, Val Loss: 1.52049
Epoch 376, Val Loss: 1.51856
Epoch 377, Val Loss: 1.51767
Epoch 378, Val Loss: 1.52016
Epoch 379, Val Loss: 1.51865
Epoch 380, Val Loss: 1.51938
Epoch 381, Val Loss: 1.53123
Epoch 382, Val Loss: 1.52000
Epoch 383, Val Loss: 1.51756
Epoch 384, Val Loss: 1.52072
Epoch 385, Val Loss: 1.51866
Epoch 386, Val Loss: 1.52002
Epoch 387, Val Loss: 1.52066
Epoch 388, Val Loss: 1.52527
Epoch 389, Val Loss: 1.52242
Epoch 390, Val Loss: 1.51880
Epoch 391, Val Loss: 1.52130
Epoch 392, Val Loss: 1.52309
Epoch 393, Val Loss: 1.51641
Epoch 394, Val Loss: 1.51391
Epoch 395, Val Loss: 1.51695
Epoch 396, Val Loss: 1.51366
Epoch 397, Val Loss: 1.51262
Epoch 398, Val Loss: 1.51567
Epoch 399, Val Loss: 1.51259
{'Log Loss - mean': 3.653576557611135, 'Log Loss - std': 0.30054832362564216, 'AUC - mean': 0.5215988877590804, 'AUC - std': 0.04888392709445305, 'Accuracy - mean': 0.7445238984569592, 'Accuracy - std': 0.018390415764624322, 'F1 score - mean': 0.6977687232472096, 'F1 score - std': 0.027540307698128947}
On Device: cuda
Epoch 0, Val Loss: 1.77885
Epoch 1, Val Loss: 1.71398
Epoch 2, Val Loss: 1.70040
Epoch 3, Val Loss: 1.68934
Epoch 4, Val Loss: 1.66496
Epoch 5, Val Loss: 1.62814
Epoch 6, Val Loss: 1.60879
Epoch 7, Val Loss: 1.59518
Epoch 8, Val Loss: 1.58614
Epoch 9, Val Loss: 1.57996
Epoch 10, Val Loss: 1.57302
Epoch 11, Val Loss: 1.57229
Epoch 12, Val Loss: 1.57237
Epoch 13, Val Loss: 1.56835
Epoch 14, Val Loss: 1.56794
Epoch 15, Val Loss: 1.56812
Epoch 16, Val Loss: 1.56555
Epoch 17, Val Loss: 1.56551
Epoch 18, Val Loss: 1.56512
Epoch 19, Val Loss: 1.56324
Epoch 20, Val Loss: 1.56377
Epoch 21, Val Loss: 1.56316
Epoch 22, Val Loss: 1.56156
Epoch 23, Val Loss: 1.56226
Epoch 24, Val Loss: 1.56140
Epoch 25, Val Loss: 1.56008
Epoch 26, Val Loss: 1.56065
Epoch 27, Val Loss: 1.55980
Epoch 28, Val Loss: 1.55883
Epoch 29, Val Loss: 1.55930
Epoch 30, Val Loss: 1.55878
Epoch 31, Val Loss: 1.55780
Epoch 32, Val Loss: 1.55818
Epoch 33, Val Loss: 1.55762
Epoch 34, Val Loss: 1.55716
Epoch 35, Val Loss: 1.55687
Epoch 36, Val Loss: 1.55724
Epoch 37, Val Loss: 1.55614
Epoch 38, Val Loss: 1.55643
Epoch 39, Val Loss: 1.55577
Epoch 40, Val Loss: 1.55613
Epoch 41, Val Loss: 1.55516
Epoch 42, Val Loss: 1.55558
Epoch 43, Val Loss: 1.55474
Epoch 44, Val Loss: 1.55523
Epoch 45, Val Loss: 1.55432
Epoch 46, Val Loss: 1.55510
Epoch 47, Val Loss: 1.55406
Epoch 48, Val Loss: 1.55457
Epoch 49, Val Loss: 1.55359
Epoch 50, Val Loss: 1.55377
Epoch 51, Val Loss: 1.55305
Epoch 52, Val Loss: 1.55352
Epoch 53, Val Loss: 1.55238
Epoch 54, Val Loss: 1.55197
Epoch 55, Val Loss: 1.55047
Epoch 56, Val Loss: 1.54965
Epoch 57, Val Loss: 1.54892
Epoch 58, Val Loss: 1.54963
Epoch 59, Val Loss: 1.54872
Epoch 60, Val Loss: 1.54927
Epoch 61, Val Loss: 1.54839
Epoch 62, Val Loss: 1.54949
Epoch 63, Val Loss: 1.54820
Epoch 64, Val Loss: 1.54974
Epoch 65, Val Loss: 1.54846
Epoch 66, Val Loss: 1.54896
Epoch 67, Val Loss: 1.54801
Epoch 68, Val Loss: 1.54863
Epoch 69, Val Loss: 1.54761
Epoch 70, Val Loss: 1.54853
Epoch 71, Val Loss: 1.54755
Epoch 72, Val Loss: 1.54789
Epoch 73, Val Loss: 1.54706
Epoch 74, Val Loss: 1.54757
Epoch 75, Val Loss: 1.54667
Epoch 76, Val Loss: 1.54738
Epoch 77, Val Loss: 1.54655
Epoch 78, Val Loss: 1.54710
Epoch 79, Val Loss: 1.54596
Epoch 80, Val Loss: 1.54669
Epoch 81, Val Loss: 1.54566
Epoch 82, Val Loss: 1.54679
Epoch 83, Val Loss: 1.54542
Epoch 84, Val Loss: 1.54647
Epoch 85, Val Loss: 1.54552
Epoch 86, Val Loss: 1.54608
Epoch 87, Val Loss: 1.54498
Epoch 88, Val Loss: 1.54555
Epoch 89, Val Loss: 1.54458
Epoch 90, Val Loss: 1.54499
Epoch 91, Val Loss: 1.54399
Epoch 92, Val Loss: 1.54513
Epoch 93, Val Loss: 1.54367
Epoch 94, Val Loss: 1.54453
Epoch 95, Val Loss: 1.54363
Epoch 96, Val Loss: 1.54468
Epoch 97, Val Loss: 1.54355
Epoch 98, Val Loss: 1.54467
Epoch 99, Val Loss: 1.54321
Epoch 100, Val Loss: 1.54414
Epoch 101, Val Loss: 1.54289
Epoch 102, Val Loss: 1.54488
Epoch 103, Val Loss: 1.54383
Epoch 104, Val Loss: 1.54412
Epoch 105, Val Loss: 1.54277
Epoch 106, Val Loss: 1.54417
Epoch 107, Val Loss: 1.54194
Epoch 108, Val Loss: 1.54353
Epoch 109, Val Loss: 1.54256
Epoch 110, Val Loss: 1.54328
Epoch 111, Val Loss: 1.54115
Epoch 112, Val Loss: 1.54303
Epoch 113, Val Loss: 1.54149
Epoch 114, Val Loss: 1.54201
Epoch 115, Val Loss: 1.54204
Epoch 116, Val Loss: 1.54236
Epoch 117, Val Loss: 1.54074
Epoch 118, Val Loss: 1.54264
Epoch 119, Val Loss: 1.54146
Epoch 120, Val Loss: 1.54176
Epoch 121, Val Loss: 1.54175
Epoch 122, Val Loss: 1.54152
Epoch 123, Val Loss: 1.54285
Epoch 124, Val Loss: 1.54348
Epoch 125, Val Loss: 1.54296
Epoch 126, Val Loss: 1.54218
Epoch 127, Val Loss: 1.54161
Epoch 128, Val Loss: 1.54090
Epoch 129, Val Loss: 1.54181
Epoch 130, Val Loss: 1.54075
Epoch 131, Val Loss: 1.54246
Epoch 132, Val Loss: 1.54074
Epoch 133, Val Loss: 1.53998
Epoch 134, Val Loss: 1.54228
Epoch 135, Val Loss: 1.54252
Epoch 136, Val Loss: 1.54063
Epoch 137, Val Loss: 1.54345
Epoch 138, Val Loss: 1.54176
Epoch 139, Val Loss: 1.54118
Epoch 140, Val Loss: 1.54455
Epoch 141, Val Loss: 1.54419
Epoch 142, Val Loss: 1.54008
Epoch 143, Val Loss: 1.54064
Epoch 144, Val Loss: 1.53863
Epoch 145, Val Loss: 1.53906
Epoch 146, Val Loss: 1.54126
Epoch 147, Val Loss: 1.54122
Epoch 148, Val Loss: 1.53839
Epoch 149, Val Loss: 1.53847
Epoch 150, Val Loss: 1.53726
Epoch 151, Val Loss: 1.53780
Epoch 152, Val Loss: 1.53936
Epoch 153, Val Loss: 1.53985
Epoch 154, Val Loss: 1.53720
Epoch 155, Val Loss: 1.53768
Epoch 156, Val Loss: 1.53680
Epoch 157, Val Loss: 1.53681
Epoch 158, Val Loss: 1.53728
Epoch 159, Val Loss: 1.53922
Epoch 160, Val Loss: 1.53763
Epoch 161, Val Loss: 1.53781
Epoch 162, Val Loss: 1.53620
Epoch 163, Val Loss: 1.53597
Epoch 164, Val Loss: 1.53597
Epoch 165, Val Loss: 1.53680
Epoch 166, Val Loss: 1.53620
Epoch 167, Val Loss: 1.53618
Epoch 168, Val Loss: 1.53695
Epoch 169, Val Loss: 1.53666
Epoch 170, Val Loss: 1.53740
Epoch 171, Val Loss: 1.53564
Epoch 172, Val Loss: 1.53691
Epoch 173, Val Loss: 1.53510
Epoch 174, Val Loss: 1.53604
Epoch 175, Val Loss: 1.53581
Epoch 176, Val Loss: 1.53662
Epoch 177, Val Loss: 1.53695
Epoch 178, Val Loss: 1.53763
Epoch 179, Val Loss: 1.53823
Epoch 180, Val Loss: 1.53770
Epoch 181, Val Loss: 1.53650
Epoch 182, Val Loss: 1.53529
Epoch 183, Val Loss: 1.53530
Epoch 184, Val Loss: 1.53626
Epoch 185, Val Loss: 1.53587
Epoch 186, Val Loss: 1.53681
Epoch 187, Val Loss: 1.53710
Epoch 188, Val Loss: 1.53497
Epoch 189, Val Loss: 1.53440
Epoch 190, Val Loss: 1.53238
Epoch 191, Val Loss: 1.53242
Epoch 192, Val Loss: 1.53407
Epoch 193, Val Loss: 1.53419
Epoch 194, Val Loss: 1.53487
Epoch 195, Val Loss: 1.53653
Epoch 196, Val Loss: 1.53291
Epoch 197, Val Loss: 1.53280
Epoch 198, Val Loss: 1.53157
Epoch 199, Val Loss: 1.53151
Epoch 200, Val Loss: 1.53248
Epoch 201, Val Loss: 1.53398
Epoch 202, Val Loss: 1.53235
Epoch 203, Val Loss: 1.53358
Epoch 204, Val Loss: 1.53118
Epoch 205, Val Loss: 1.53164
Epoch 206, Val Loss: 1.53099
Epoch 207, Val Loss: 1.53161
Epoch 208, Val Loss: 1.53071
Epoch 209, Val Loss: 1.53057
Epoch 210, Val Loss: 1.53135
Epoch 211, Val Loss: 1.53074
Epoch 212, Val Loss: 1.53170
Epoch 213, Val Loss: 1.53016
Epoch 214, Val Loss: 1.53027
Epoch 215, Val Loss: 1.53209
Epoch 216, Val Loss: 1.53180
Epoch 217, Val Loss: 1.53231
Epoch 218, Val Loss: 1.53433
Epoch 219, Val Loss: 1.53085
Epoch 220, Val Loss: 1.52913
Epoch 221, Val Loss: 1.52896
Epoch 222, Val Loss: 1.52870
Epoch 223, Val Loss: 1.52913
Epoch 224, Val Loss: 1.53171
Epoch 225, Val Loss: 1.53238
Epoch 226, Val Loss: 1.53287
Epoch 227, Val Loss: 1.53346
Epoch 228, Val Loss: 1.53112
Epoch 229, Val Loss: 1.53097
Epoch 230, Val Loss: 1.53195
Epoch 231, Val Loss: 1.52938
Epoch 232, Val Loss: 1.52862
Epoch 233, Val Loss: 1.52966
Epoch 234, Val Loss: 1.52948
Epoch 235, Val Loss: 1.53019
Epoch 236, Val Loss: 1.53057
Epoch 237, Val Loss: 1.52977
Epoch 238, Val Loss: 1.52772
Epoch 239, Val Loss: 1.52836
Epoch 240, Val Loss: 1.53051
Epoch 241, Val Loss: 1.53027
Epoch 242, Val Loss: 1.53142
Epoch 243, Val Loss: 1.53165
Epoch 244, Val Loss: 1.52798
Epoch 245, Val Loss: 1.52742
Epoch 246, Val Loss: 1.52634
Epoch 247, Val Loss: 1.52670
Epoch 248, Val Loss: 1.52717
Epoch 249, Val Loss: 1.52780
Epoch 250, Val Loss: 1.52776
Epoch 251, Val Loss: 1.52776
Epoch 252, Val Loss: 1.52795
Epoch 253, Val Loss: 1.52722
Epoch 254, Val Loss: 1.52720
Epoch 255, Val Loss: 1.52920
Epoch 256, Val Loss: 1.52856
Epoch 257, Val Loss: 1.52930
Epoch 258, Val Loss: 1.53131
Epoch 259, Val Loss: 1.52861
Epoch 260, Val Loss: 1.52901
Epoch 261, Val Loss: 1.53059
Epoch 262, Val Loss: 1.52850
Epoch 263, Val Loss: 1.52701
Epoch 264, Val Loss: 1.52761
Epoch 265, Val Loss: 1.52727
Epoch 266, Val Loss: 1.52801
Epoch 267, Val Loss: 1.52788
Epoch 268, Val Loss: 1.53045
Epoch 269, Val Loss: 1.52666
Epoch 270, Val Loss: 1.52694
Epoch 271, Val Loss: 1.52608
Epoch 272, Val Loss: 1.52690
Epoch 273, Val Loss: 1.53303
Epoch 274, Val Loss: 1.53242
Epoch 275, Val Loss: 1.52826
Epoch 276, Val Loss: 1.52767
Epoch 277, Val Loss: 1.52568
Epoch 278, Val Loss: 1.52483
Epoch 279, Val Loss: 1.53210
Epoch 280, Val Loss: 1.52830
Epoch 281, Val Loss: 1.52866
Epoch 282, Val Loss: 1.52644
Epoch 283, Val Loss: 1.52561
Epoch 284, Val Loss: 1.52706
Epoch 285, Val Loss: 1.52658
Epoch 286, Val Loss: 1.52571
Epoch 287, Val Loss: 1.52548
Epoch 288, Val Loss: 1.52409
Epoch 289, Val Loss: 1.52553
Epoch 290, Val Loss: 1.52592
Epoch 291, Val Loss: 1.52821
Epoch 292, Val Loss: 1.52796
Epoch 293, Val Loss: 1.52684
Epoch 294, Val Loss: 1.52633
Epoch 295, Val Loss: 1.52568
Epoch 296, Val Loss: 1.52425
Epoch 297, Val Loss: 1.52557
Epoch 298, Val Loss: 1.52456
Epoch 299, Val Loss: 1.52684
Epoch 300, Val Loss: 1.52875
Epoch 301, Val Loss: 1.52525
Epoch 302, Val Loss: 1.52814
Epoch 303, Val Loss: 1.52884
Epoch 304, Val Loss: 1.52813
Epoch 305, Val Loss: 1.52782
Epoch 306, Val Loss: 1.52788
Epoch 307, Val Loss: 1.52418
Epoch 308, Val Loss: 1.52437
Epoch 309, Val Loss: 1.52324
Epoch 310, Val Loss: 1.52392
Epoch 311, Val Loss: 1.52573
Epoch 312, Val Loss: 1.52490
Epoch 313, Val Loss: 1.52399
Epoch 314, Val Loss: 1.52370
Epoch 315, Val Loss: 1.52265
Epoch 316, Val Loss: 1.52293
Epoch 317, Val Loss: 1.52631
Epoch 318, Val Loss: 1.52407
Epoch 319, Val Loss: 1.52644
Epoch 320, Val Loss: 1.52422
Epoch 321, Val Loss: 1.52312
Epoch 322, Val Loss: 1.52286
Epoch 323, Val Loss: 1.52333
Epoch 324, Val Loss: 1.52426
Epoch 325, Val Loss: 1.52847
Epoch 326, Val Loss: 1.52729
Epoch 327, Val Loss: 1.52622
Epoch 328, Val Loss: 1.52396
Epoch 329, Val Loss: 1.52147
Epoch 330, Val Loss: 1.52187
Epoch 331, Val Loss: 1.52618
Epoch 332, Val Loss: 1.52437
Epoch 333, Val Loss: 1.52309
Epoch 334, Val Loss: 1.52206
Epoch 335, Val Loss: 1.52200
Epoch 336, Val Loss: 1.52112
Epoch 337, Val Loss: 1.52244
Epoch 338, Val Loss: 1.52345
Epoch 339, Val Loss: 1.52253
Epoch 340, Val Loss: 1.52278
Epoch 341, Val Loss: 1.52670
Epoch 342, Val Loss: 1.52229
Epoch 343, Val Loss: 1.52775
Epoch 344, Val Loss: 1.52713
Epoch 345, Val Loss: 1.52275
Epoch 346, Val Loss: 1.52447
Epoch 347, Val Loss: 1.52375
Epoch 348, Val Loss: 1.52524
Epoch 349, Val Loss: 1.53632
Epoch 350, Val Loss: 1.52604
Epoch 351, Val Loss: 1.52470
Epoch 352, Val Loss: 1.52336
Epoch 353, Val Loss: 1.52698
Epoch 354, Val Loss: 1.53228
Epoch 355, Val Loss: 1.52819
Epoch 356, Val Loss: 1.52538
Epoch 357, Val Loss: 1.52943
Epoch 358, Val Loss: 1.52357
Epoch 359, Val Loss: 1.52025
Epoch 360, Val Loss: 1.52037
Epoch 361, Val Loss: 1.52031
Epoch 362, Val Loss: 1.51966
Epoch 363, Val Loss: 1.51935
Epoch 364, Val Loss: 1.52211
Epoch 365, Val Loss: 1.52284
Epoch 366, Val Loss: 1.52060
Epoch 367, Val Loss: 1.52053
Epoch 368, Val Loss: 1.52334
Epoch 369, Val Loss: 1.52442
Epoch 370, Val Loss: 1.52211
Epoch 371, Val Loss: 1.52054
Epoch 372, Val Loss: 1.52682
Epoch 373, Val Loss: 1.53377
Epoch 374, Val Loss: 1.52384
Epoch 375, Val Loss: 1.52429
Epoch 376, Val Loss: 1.52811
Epoch 377, Val Loss: 1.52262
Epoch 378, Val Loss: 1.52148
Epoch 379, Val Loss: 1.51986
Epoch 380, Val Loss: 1.51875
Epoch 381, Val Loss: 1.51828
Epoch 382, Val Loss: 1.51949
Epoch 383, Val Loss: 1.52023
Epoch 384, Val Loss: 1.51850
Epoch 385, Val Loss: 1.51890
Epoch 386, Val Loss: 1.51973
Epoch 387, Val Loss: 1.52068
Epoch 388, Val Loss: 1.51897
Epoch 389, Val Loss: 1.51974
Epoch 390, Val Loss: 1.51836
Epoch 391, Val Loss: 1.52030
Epoch 392, Val Loss: 1.52137
Epoch 393, Val Loss: 1.52153
Epoch 394, Val Loss: 1.52230
Epoch 395, Val Loss: 1.52115
Epoch 396, Val Loss: 1.52160
Epoch 397, Val Loss: 1.52686
Epoch 398, Val Loss: 1.52079
Epoch 399, Val Loss: 1.52095
{'Log Loss - mean': 3.7281994986999987, 'Log Loss - std': 0.29060750357809745, 'AUC - mean': 0.5126028124824683, 'AUC - std': 0.045111161116504844, 'Accuracy - mean': 0.7399711238737, 'Accuracy - std': 0.017771854523789085, 'F1 score - mean': 0.6917222763926352, 'F1 score - std': 0.02604860782798759}
On Device: cuda
Epoch 0, Val Loss: 1.80068
Epoch 1, Val Loss: 1.71390
Epoch 2, Val Loss: 1.69434
Epoch 3, Val Loss: 1.66300
Epoch 4, Val Loss: 1.63000
Epoch 5, Val Loss: 1.61572
Epoch 6, Val Loss: 1.60599
Epoch 7, Val Loss: 1.59772
Epoch 8, Val Loss: 1.58637
Epoch 9, Val Loss: 1.58247
Epoch 10, Val Loss: 1.57915
Epoch 11, Val Loss: 1.57602
Epoch 12, Val Loss: 1.57158
Epoch 13, Val Loss: 1.57246
Epoch 14, Val Loss: 1.57086
Epoch 15, Val Loss: 1.56891
Epoch 16, Val Loss: 1.56795
Epoch 17, Val Loss: 1.56795
Epoch 18, Val Loss: 1.56788
Epoch 19, Val Loss: 1.56614
Epoch 20, Val Loss: 1.56676
Epoch 21, Val Loss: 1.56720
Epoch 22, Val Loss: 1.56469
Epoch 23, Val Loss: 1.56567
Epoch 24, Val Loss: 1.56593
Epoch 25, Val Loss: 1.56338
Epoch 26, Val Loss: 1.56387
Epoch 27, Val Loss: 1.56327
Epoch 28, Val Loss: 1.55977
Epoch 29, Val Loss: 1.55656
Epoch 30, Val Loss: 1.54799
Epoch 31, Val Loss: 1.53632
Epoch 32, Val Loss: 1.53412
Epoch 33, Val Loss: 1.53285
Epoch 34, Val Loss: 1.53162
Epoch 35, Val Loss: 1.53227
Epoch 36, Val Loss: 1.53127
Epoch 37, Val Loss: 1.53021
Epoch 38, Val Loss: 1.53093
Epoch 39, Val Loss: 1.53029
Epoch 40, Val Loss: 1.52900
Epoch 41, Val Loss: 1.52970
Epoch 42, Val Loss: 1.52951
Epoch 43, Val Loss: 1.52793
Epoch 44, Val Loss: 1.52816
Epoch 45, Val Loss: 1.52833
Epoch 46, Val Loss: 1.52688
Epoch 47, Val Loss: 1.52662
Epoch 48, Val Loss: 1.52649
Epoch 49, Val Loss: 1.52609
Epoch 50, Val Loss: 1.52578
Epoch 51, Val Loss: 1.52527
Epoch 52, Val Loss: 1.52542
Epoch 53, Val Loss: 1.52487
Epoch 54, Val Loss: 1.52574
Epoch 55, Val Loss: 1.52474
Epoch 56, Val Loss: 1.52542
Epoch 57, Val Loss: 1.52387
Epoch 58, Val Loss: 1.52432
Epoch 59, Val Loss: 1.52310
Epoch 60, Val Loss: 1.52382
Epoch 61, Val Loss: 1.52271
Epoch 62, Val Loss: 1.52348
Epoch 63, Val Loss: 1.52240
Epoch 64, Val Loss: 1.52296
Epoch 65, Val Loss: 1.52199
Epoch 66, Val Loss: 1.52276
Epoch 67, Val Loss: 1.52154
Epoch 68, Val Loss: 1.52247
Epoch 69, Val Loss: 1.52125
Epoch 70, Val Loss: 1.52241
Epoch 71, Val Loss: 1.52098
Epoch 72, Val Loss: 1.52270
Epoch 73, Val Loss: 1.52092
Epoch 74, Val Loss: 1.52215
Epoch 75, Val Loss: 1.52049
Epoch 76, Val Loss: 1.52093
Epoch 77, Val Loss: 1.51981
Epoch 78, Val Loss: 1.52102
Epoch 79, Val Loss: 1.51947
Epoch 80, Val Loss: 1.52189
Epoch 81, Val Loss: 1.51984
Epoch 82, Val Loss: 1.52061
Epoch 83, Val Loss: 1.52138
Epoch 84, Val Loss: 1.51945
Epoch 85, Val Loss: 1.51804
Epoch 86, Val Loss: 1.52079
Epoch 87, Val Loss: 1.51930
Epoch 88, Val Loss: 1.52210
Epoch 89, Val Loss: 1.51977
Epoch 90, Val Loss: 1.52011
Epoch 91, Val Loss: 1.51817
Epoch 92, Val Loss: 1.52067
Epoch 93, Val Loss: 1.51813
Epoch 94, Val Loss: 1.51733
Epoch 95, Val Loss: 1.51950
Epoch 96, Val Loss: 1.51867
Epoch 97, Val Loss: 1.51809
Epoch 98, Val Loss: 1.51989
Epoch 99, Val Loss: 1.51767
Epoch 100, Val Loss: 1.51702
Epoch 101, Val Loss: 1.51939
Epoch 102, Val Loss: 1.51620
Epoch 103, Val Loss: 1.51514
Epoch 104, Val Loss: 1.51599
Epoch 105, Val Loss: 1.51829
Epoch 106, Val Loss: 1.51632
Epoch 107, Val Loss: 1.51857
Epoch 108, Val Loss: 1.51693
Epoch 109, Val Loss: 1.51788
Epoch 110, Val Loss: 1.51941
Epoch 111, Val Loss: 1.51950
Epoch 112, Val Loss: 1.51630
Epoch 113, Val Loss: 1.51681
Epoch 114, Val Loss: 1.51748
Epoch 115, Val Loss: 1.52011
Epoch 116, Val Loss: 1.51671
Epoch 117, Val Loss: 1.51999
Epoch 118, Val Loss: 1.51580
Epoch 119, Val Loss: 1.51531
Epoch 120, Val Loss: 1.51835
Epoch 121, Val Loss: 1.51492
Epoch 122, Val Loss: 1.51471
Epoch 123, Val Loss: 1.51573
Epoch 124, Val Loss: 1.51373
Epoch 125, Val Loss: 1.51504
Epoch 126, Val Loss: 1.51380
Epoch 127, Val Loss: 1.51381
Epoch 128, Val Loss: 1.51421
Epoch 129, Val Loss: 1.51388
Epoch 130, Val Loss: 1.51309
Epoch 131, Val Loss: 1.51463
Epoch 132, Val Loss: 1.51457
Epoch 133, Val Loss: 1.51555
Epoch 134, Val Loss: 1.51654
Epoch 135, Val Loss: 1.51625
Epoch 136, Val Loss: 1.51642
Epoch 137, Val Loss: 1.51456
Epoch 138, Val Loss: 1.51625
Epoch 139, Val Loss: 1.51276
Epoch 140, Val Loss: 1.51237
Epoch 141, Val Loss: 1.51658
Epoch 142, Val Loss: 1.51650
Epoch 143, Val Loss: 1.51608
Epoch 144, Val Loss: 1.51691
Epoch 145, Val Loss: 1.51271
Epoch 146, Val Loss: 1.51241
Epoch 147, Val Loss: 1.51392
Epoch 148, Val Loss: 1.51222
Epoch 149, Val Loss: 1.51278
Epoch 150, Val Loss: 1.51406
Epoch 151, Val Loss: 1.51101
Epoch 152, Val Loss: 1.51065
Epoch 153, Val Loss: 1.51248
Epoch 154, Val Loss: 1.51243
Epoch 155, Val Loss: 1.51190
Epoch 156, Val Loss: 1.51260
Epoch 157, Val Loss: 1.51031
Epoch 158, Val Loss: 1.51164
Epoch 159, Val Loss: 1.51023
Epoch 160, Val Loss: 1.51019
Epoch 161, Val Loss: 1.50973
Epoch 162, Val Loss: 1.50999
Epoch 163, Val Loss: 1.51053
Epoch 164, Val Loss: 1.51029
Epoch 165, Val Loss: 1.50869
Epoch 166, Val Loss: 1.50910
Epoch 167, Val Loss: 1.51163
Epoch 168, Val Loss: 1.50929
Epoch 169, Val Loss: 1.50982
Epoch 170, Val Loss: 1.50987
Epoch 171, Val Loss: 1.50991
Epoch 172, Val Loss: 1.50985
Epoch 173, Val Loss: 1.51196
Epoch 174, Val Loss: 1.50994
Epoch 175, Val Loss: 1.50987
Epoch 176, Val Loss: 1.51405
Epoch 177, Val Loss: 1.51035
Epoch 178, Val Loss: 1.50838
Epoch 179, Val Loss: 1.51024
Epoch 180, Val Loss: 1.50738
Epoch 181, Val Loss: 1.50778
Epoch 182, Val Loss: 1.50931
Epoch 183, Val Loss: 1.51057
Epoch 184, Val Loss: 1.51123
Epoch 185, Val Loss: 1.51248
Epoch 186, Val Loss: 1.50888
Epoch 187, Val Loss: 1.51008
Epoch 188, Val Loss: 1.50829
Epoch 189, Val Loss: 1.50792
Epoch 190, Val Loss: 1.50952
Epoch 191, Val Loss: 1.51316
Epoch 192, Val Loss: 1.51047
Epoch 193, Val Loss: 1.50936
Epoch 194, Val Loss: 1.51191
Epoch 195, Val Loss: 1.50963
Epoch 196, Val Loss: 1.50770
Epoch 197, Val Loss: 1.51036
Epoch 198, Val Loss: 1.51029
Epoch 199, Val Loss: 1.50902
Epoch 200, Val Loss: 1.50718
Epoch 201, Val Loss: 1.50698
Epoch 202, Val Loss: 1.50657
Epoch 203, Val Loss: 1.50728
Epoch 204, Val Loss: 1.50652
Epoch 205, Val Loss: 1.50917
Epoch 206, Val Loss: 1.50751
Epoch 207, Val Loss: 1.50790
Epoch 208, Val Loss: 1.51023
Epoch 209, Val Loss: 1.50983
Epoch 210, Val Loss: 1.50991
Epoch 211, Val Loss: 1.51243
Epoch 212, Val Loss: 1.50943
Epoch 213, Val Loss: 1.50766
Epoch 214, Val Loss: 1.51788
Epoch 215, Val Loss: 1.50957
Epoch 216, Val Loss: 1.51038
Epoch 217, Val Loss: 1.51046
Epoch 218, Val Loss: 1.51041
Epoch 219, Val Loss: 1.50985
Epoch 220, Val Loss: 1.51296
Epoch 221, Val Loss: 1.50779
Epoch 222, Val Loss: 1.50542
Epoch 223, Val Loss: 1.50745
Epoch 224, Val Loss: 1.50501
Epoch 225, Val Loss: 1.50403
Epoch 226, Val Loss: 1.50470
Epoch 227, Val Loss: 1.50558
Epoch 228, Val Loss: 1.50553
Epoch 229, Val Loss: 1.50596
Epoch 230, Val Loss: 1.50417
Epoch 231, Val Loss: 1.50437
Epoch 232, Val Loss: 1.50574
Epoch 233, Val Loss: 1.50575
Epoch 234, Val Loss: 1.50572
Epoch 235, Val Loss: 1.50549
Epoch 236, Val Loss: 1.50531
Epoch 237, Val Loss: 1.50386
Epoch 238, Val Loss: 1.50545
Epoch 239, Val Loss: 1.50810
Epoch 240, Val Loss: 1.50786
Epoch 241, Val Loss: 1.50817
Epoch 242, Val Loss: 1.50912
Epoch 243, Val Loss: 1.50521
Epoch 244, Val Loss: 1.50448
Epoch 245, Val Loss: 1.51137
Epoch 246, Val Loss: 1.50854
Epoch 247, Val Loss: 1.50586
Epoch 248, Val Loss: 1.50968
Epoch 249, Val Loss: 1.50611
Epoch 250, Val Loss: 1.50919
Epoch 251, Val Loss: 1.52029
Epoch 252, Val Loss: 1.51069
Epoch 253, Val Loss: 1.50818
Epoch 254, Val Loss: 1.50493
Epoch 255, Val Loss: 1.50460
Epoch 256, Val Loss: 1.50629
Epoch 257, Val Loss: 1.50520
Epoch 258, Val Loss: 1.50415
Epoch 259, Val Loss: 1.51159
Epoch 260, Val Loss: 1.50502
Epoch 261, Val Loss: 1.50388
Epoch 262, Val Loss: 1.50587
Epoch 263, Val Loss: 1.50323
Epoch 264, Val Loss: 1.50269
Epoch 265, Val Loss: 1.50575
Epoch 266, Val Loss: 1.50298
Epoch 267, Val Loss: 1.50271
Epoch 268, Val Loss: 1.50301
Epoch 269, Val Loss: 1.50364
Epoch 270, Val Loss: 1.50484
Epoch 271, Val Loss: 1.50434
Epoch 272, Val Loss: 1.50372
Epoch 273, Val Loss: 1.50365
Epoch 274, Val Loss: 1.50367
Epoch 275, Val Loss: 1.50578
Epoch 276, Val Loss: 1.50599
Epoch 277, Val Loss: 1.50430
Epoch 278, Val Loss: 1.50493
Epoch 279, Val Loss: 1.50245
Epoch 280, Val Loss: 1.50396
Epoch 281, Val Loss: 1.50629
Epoch 282, Val Loss: 1.50683
Epoch 283, Val Loss: 1.50474
Epoch 284, Val Loss: 1.50535
Epoch 285, Val Loss: 1.50371
Epoch 286, Val Loss: 1.50163
Epoch 287, Val Loss: 1.50542
Epoch 288, Val Loss: 1.50288
Epoch 289, Val Loss: 1.50276
Epoch 290, Val Loss: 1.50377
Epoch 291, Val Loss: 1.50466
Epoch 292, Val Loss: 1.50119
Epoch 293, Val Loss: 1.50227
Epoch 294, Val Loss: 1.50264
Epoch 295, Val Loss: 1.50149
Epoch 296, Val Loss: 1.50208
Epoch 297, Val Loss: 1.50602
Epoch 298, Val Loss: 1.50294
Epoch 299, Val Loss: 1.50439
Epoch 300, Val Loss: 1.50744
Epoch 301, Val Loss: 1.50429
Epoch 302, Val Loss: 1.50180
Epoch 303, Val Loss: 1.50355
Epoch 304, Val Loss: 1.50069
Epoch 305, Val Loss: 1.50033
Epoch 306, Val Loss: 1.50456
Epoch 307, Val Loss: 1.50149
Epoch 308, Val Loss: 1.50276
Epoch 309, Val Loss: 1.50342
Epoch 310, Val Loss: 1.50175
Epoch 311, Val Loss: 1.50196
Epoch 312, Val Loss: 1.50703
Epoch 313, Val Loss: 1.50397
Epoch 314, Val Loss: 1.50286
Epoch 315, Val Loss: 1.50199
Epoch 316, Val Loss: 1.50127
Epoch 317, Val Loss: 1.50226
Epoch 318, Val Loss: 1.50211
Epoch 319, Val Loss: 1.50299
Epoch 320, Val Loss: 1.50184
Epoch 321, Val Loss: 1.50216
Epoch 322, Val Loss: 1.50066
Epoch 323, Val Loss: 1.50330
Epoch 324, Val Loss: 1.50132
Epoch 325, Val Loss: 1.50190
Epoch 326, Val Loss: 1.50034
Epoch 327, Val Loss: 1.50424
Epoch 328, Val Loss: 1.50401
Epoch 329, Val Loss: 1.50206
Epoch 330, Val Loss: 1.50211
Epoch 331, Val Loss: 1.49996
Epoch 332, Val Loss: 1.49982
Epoch 333, Val Loss: 1.50038
Epoch 334, Val Loss: 1.49872
Epoch 335, Val Loss: 1.49942
Epoch 336, Val Loss: 1.49971
Epoch 337, Val Loss: 1.49845
Epoch 338, Val Loss: 1.49891
Epoch 339, Val Loss: 1.50207
Epoch 340, Val Loss: 1.50205
Epoch 341, Val Loss: 1.50024
Epoch 342, Val Loss: 1.50122
Epoch 343, Val Loss: 1.49855
Epoch 344, Val Loss: 1.49921
Epoch 345, Val Loss: 1.50432
Epoch 346, Val Loss: 1.50342
Epoch 347, Val Loss: 1.50112
Epoch 348, Val Loss: 1.49942
Epoch 349, Val Loss: 1.49747
Epoch 350, Val Loss: 1.50161
Epoch 351, Val Loss: 1.49708
Epoch 352, Val Loss: 1.49606
Epoch 353, Val Loss: 1.50205
Epoch 354, Val Loss: 1.49955
Epoch 355, Val Loss: 1.50504
Epoch 356, Val Loss: 1.49731
Epoch 357, Val Loss: 1.49658
Epoch 358, Val Loss: 1.50454
Epoch 359, Val Loss: 1.49828
Epoch 360, Val Loss: 1.49715
Epoch 361, Val Loss: 1.49739
Epoch 362, Val Loss: 1.49435
Epoch 363, Val Loss: 1.49412
Epoch 364, Val Loss: 1.49285
Epoch 365, Val Loss: 1.49321
Epoch 366, Val Loss: 1.49280
Epoch 367, Val Loss: 1.49364
Epoch 368, Val Loss: 1.49395
Epoch 369, Val Loss: 1.49446
Epoch 370, Val Loss: 1.49312
Epoch 371, Val Loss: 1.49641
Epoch 372, Val Loss: 1.49222
Epoch 373, Val Loss: 1.49148
Epoch 374, Val Loss: 1.49270
Epoch 375, Val Loss: 1.49142
Epoch 376, Val Loss: 1.49677
Epoch 377, Val Loss: 1.49457
Epoch 378, Val Loss: 1.49511
Epoch 379, Val Loss: 1.50302
Epoch 380, Val Loss: 1.50194
Epoch 381, Val Loss: 1.50131
Epoch 382, Val Loss: 1.49918
Epoch 383, Val Loss: 1.50095
Epoch 384, Val Loss: 1.49943
Epoch 385, Val Loss: 1.49694
Epoch 386, Val Loss: 1.49735
Epoch 387, Val Loss: 1.50416
Epoch 388, Val Loss: 1.50499
Epoch 389, Val Loss: 1.50301
Epoch 390, Val Loss: 1.51430
Epoch 391, Val Loss: 1.50645
Epoch 392, Val Loss: 1.49607
Epoch 393, Val Loss: 1.51993
Epoch 394, Val Loss: 1.50293
Epoch 395, Val Loss: 1.49820
Epoch 396, Val Loss: 1.49506
Epoch 397, Val Loss: 1.49637
Epoch 398, Val Loss: 1.49860
Epoch 399, Val Loss: 1.49374
{'Log Loss - mean': 3.736216634635825, 'Log Loss - std': 0.2604213408750697, 'AUC - mean': 0.5075222039027881, 'AUC - std': 0.041608458514863146, 'Accuracy - mean': 0.7384356519603565, 'Accuracy - std': 0.016189556712845624, 'F1 score - mean': 0.6903400492393892, 'F1 score - std': 0.023462015758108246}
{'Log Loss - mean': 3.736216634635825, 'Log Loss - std': 0.2604213408750697, 'AUC - mean': 0.5075222039027881, 'AUC - std': 0.041608458514863146, 'Accuracy - mean': 0.7384356519603565, 'Accuracy - std': 0.016189556712845624, 'F1 score - mean': 0.6903400492393892, 'F1 score - std': 0.023462015758108246}
(863.9583980799998, 0.1828190800000357)
Wrote profile results to train.py.lprof
Timer unit: 1e-06 s

Total time: 6748.5 s
File: /opt/notebooks/models/basemodel_torch.py
Function: fit at line 38

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    38                                               @profile
    39                                               def fit(self, X, y, X_val=None, y_val=None):
    40         5       1009.4    201.9      0.0          optimizer = optim.AdamW(self.model.parameters(), lr=self.params["learning_rate"])
    41                                           
    42         5      62857.0  12571.4      0.0          X = torch.tensor(X).float()
    43         5      19017.4   3803.5      0.0          X_val = torch.tensor(X_val).float()
    44                                           
    45         5       3165.1    633.0      0.0          y = torch.tensor(y)
    46         5        652.8    130.6      0.0          y_val = torch.tensor(y_val)
    47                                           
    48         5         14.7      2.9      0.0          if self.args.objective == "regression":
    49                                                       loss_func = nn.MSELoss()
    50                                                       y = y.float()
    51                                                       y_val = y_val.float()
    52         5          2.6      0.5      0.0          elif self.args.objective == "classification":
    53         5        831.4    166.3      0.0              loss_func = nn.CrossEntropyLoss()
    54                                                   else:
    55                                                       loss_func = nn.BCEWithLogitsLoss()
    56                                                       y = y.float()
    57                                                       y_val = y_val.float()
    58                                           
    59         5         81.5     16.3      0.0          train_dataset = TensorDataset(X, y)
    60        10        667.4     66.7      0.0          train_loader = DataLoader(dataset=train_dataset, batch_size=self.args.batch_size, shuffle=False,
    61         5          1.7      0.3      0.0                                    num_workers=4)
    62                                           
    63         5         34.4      6.9      0.0          val_dataset = TensorDataset(X_val, y_val)
    64         5        241.1     48.2      0.0          val_loader = DataLoader(dataset=val_dataset, batch_size=self.args.val_batch_size, shuffle=False)
    65                                           
    66         5         11.6      2.3      0.0          min_val_loss = float("inf")
    67         5          1.4      0.3      0.0          min_val_loss_idx = 0
    68                                           
    69         5          2.1      0.4      0.0          loss_history = []
    70         5          1.4      0.3      0.0          val_loss_history = []
    71                                           
    72      2005       1733.9      0.9      0.0          for epoch in range(self.args.epochs):
    73     60000 3446585903.9  57443.1     51.1              for i, (batch_X, batch_y) in enumerate(train_loader): # costy
    74                                           
    75     58000  162530806.4   2802.3      2.4                  out = self.model(batch_X.to(self.device)) # costy
    76                                           
    77     58000     203311.8      3.5      0.0                  if self.args.objective == "regression" or self.args.objective == "binary":
    78                                                               out = out.squeeze()
    79                                           
    80     58000  300197220.4   5175.8      4.4                  loss = loss_func(out, batch_y.to(self.device))
    81     58000   43431881.4    748.8      0.6                  loss_history.append(loss.item())
    82                                           
    83     58000   21903628.2    377.6      0.3                  optimizer.zero_grad()
    84     58000   96187105.9   1658.4      1.4                  loss.backward() # costy
    85     58000  153801584.5   2651.8      2.3                  optimizer.step() # costy
    86                                           
    87                                                       # Early Stopping
    88      2000     549918.4    275.0      0.0              val_loss = 0.0
    89      2000        924.4      0.5      0.0              val_dim = 0
    90     18000 2434312323.0 135239.6     36.1              for val_i, (batch_val_X, batch_val_y) in enumerate(val_loader):
    91     16000   24150490.7   1509.4      0.4                  out = self.model(batch_val_X.to(self.device))
    92                                           
    93     16000      60719.9      3.8      0.0                  if self.args.objective == "regression" or self.args.objective == "binary":
    94                                                               out = out.squeeze()
    95                                           
    96     16000   61662910.8   3853.9      0.9                  val_loss += loss_func(out, batch_val_y.to(self.device))
    97     16000      16655.7      1.0      0.0                  val_dim += 1
    98                                           
    99      2000      76456.1     38.2      0.0              val_loss /= val_dim
   100      2000     569736.6    284.9      0.0              val_loss_history.append(val_loss.item())
   101                                           
   102      2000     259903.9    130.0      0.0              print("Epoch %d, Val Loss: %.5f" % (epoch, val_loss))
   103                                           
   104      2000     664554.1    332.3      0.0              if val_loss < min_val_loss:
   105       528      99999.5    189.4      0.0                  min_val_loss = val_loss
   106       528        293.8      0.6      0.0                  min_val_loss_idx = epoch
   107                                           
   108                                                           # Save the currently best model
   109       528    1117015.2   2115.6      0.0                  self.save_model(filename_extension="best", directory="tmp")
   110                                           
   111      2000       8718.2      4.4      0.0              if min_val_loss_idx + self.args.early_stopping_rounds < epoch:
   112                                                           print("Validation loss has not improved for %d steps!" % self.args.early_stopping_rounds)
   113                                                           print("Early stopping applies.")
   114                                                           break
   115                                           
   116                                                   # Load best model
   117         5      15891.4   3178.3      0.0          self.load_model(filename_extension="best", directory="tmp")
   118         5          2.1      0.4      0.0          return loss_history, val_loss_history

