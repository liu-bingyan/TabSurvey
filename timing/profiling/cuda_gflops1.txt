GFLO is 26815.91
Should take 16.76 seconds on a 5 TFLOPS machine
device: cuda
Epoch [20/300], Loss: 1.6778
Epoch [40/300], Loss: 1.6778
Epoch [60/300], Loss: 1.6778
Epoch [80/300], Loss: 1.6778
Epoch [100/300], Loss: 1.6778
Epoch [120/300], Loss: 1.6778
Epoch [140/300], Loss: 1.6778
Epoch [160/300], Loss: 1.6778
Epoch [180/300], Loss: 1.6778
Epoch [200/300], Loss: 1.6778
Epoch [220/300], Loss: 1.6778
Epoch [240/300], Loss: 1.6778
Epoch [260/300], Loss: 1.6778
Epoch [280/300], Loss: 1.6778
Epoch [300/300], Loss: 1.6778
Test Loss: 1.6778
total_timer : 18.1210903
epoch_timer : 0.0603952006666666
Wrote profile results to __gflops1.py.lprof
Timer unit: 1e-06 s

Total time: 19.9715 s
File: __gflops1.py
Function: run at line 28

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    28                                           @profile
    29                                           def run(args):
    30         1          1.0      1.0      0.0      input_size = 54
    31         1          0.1      0.1      0.0      hidden_dim = 99
    32         1          0.2      0.2      0.0      num_samples = 581012
    33         1          0.1      0.1      0.0      num_epochs = 300
    34         1          0.2      0.2      0.0      learning_rate = 7.0e-4
    35                                           
    36                                               # Create an instance of the LinearModel
    37                                              # model = LinearModel(input_size, hidden_dim)
    38                                               
    39         1       1728.9   1728.9      0.0      model = MLP(input_size, hidden_dim)
    40                                           
    41         1          0.4      0.4      0.0      num_connections  = model.connections
    42         1          2.7      2.7      0.0      GFLO = num_epochs*6*num_samples*num_connections / 1e9
    43         1          6.1      6.1      0.0      print(f"GFLO is {GFLO:.2f}")
    44         1          1.8      1.8      0.0      print(f"Should take {GFLO/1600:.2f} seconds on a 5 TFLOPS machine")
    45                                           
    46                                               # Create dummy data
    47         1     427235.9 427235.9      2.1      x, y = datasets.fetch_covtype(return_X_y=True)
    48         1      23849.2  23849.2      0.1      x = torch.tensor(x, dtype=torch.float32)
    49         1        514.6    514.6      0.0      y = y-1
    50         1       1019.3   1019.3      0.0      y = torch.tensor(y, dtype=torch.long)
    51         1       9300.7   9300.7      0.0      y = F.one_hot(y, num_classes=7).to(torch.float32)
    52                                               # Move the data and model to GPU if available
    53         1      27621.4  27621.4      0.1      device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    54         1    1242559.5    1e+06      6.2      x = x.to(device)
    55         1       3525.3   3525.3      0.0      y = y.to(device)
    56         1       1467.2   1467.2      0.0      model = model.to(device)
    57         1         14.8     14.8      0.0      print(f'device: {device}')
    58                                           
    59         1        130.6    130.6      0.0      criterion = nn.CrossEntropyLoss()
    60         1        175.7    175.7      0.0      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    61                                               
    62         1          4.2      4.2      0.0      total_timer = timer.Timer()
    63         1          0.9      0.9      0.0      epoch_timer = timer.Timer()
    64                                               # Train the model
    65         1          7.5      7.5      0.0      total_timer.start()
    66       301        187.5      0.6      0.0      for epoch in range(num_epochs):
    67       300        778.3      2.6      0.0          epoch_timer.start()
    68                                                   # Forward pass
    69       300    3040252.5  10134.2     15.2          outputs = model(x)
    70       300    1562685.3   5209.0      7.8          loss = criterion(outputs, y)
    71                                           
    72                                                   # Backward and optimize
    73       300      77562.2    258.5      0.4          optimizer.zero_grad()
    74       300    5536179.6  18453.9     27.7          loss.backward()
    75       300    1001037.5   3336.8      5.0          optimizer.step()
    76                                           
    77                                                   # Print progress
    78       300        409.5      1.4      0.0          if (epoch+1) % 20 == 0:
    79        15    6985834.4 465722.3     35.0              print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
    80                                           
    81       300       3029.0     10.1      0.0          epoch_timer.end()
    82                                           
    83         1          2.3      2.3      0.0      total_timer.end()
    84                                               
    85                                               # Test the model
    86         1        118.1    118.1      0.0      model.eval()
    87         1         16.9     16.9      0.0      with torch.no_grad():
    88         1        506.0    506.0      0.0          test_outputs = model(x)
    89         1        139.5    139.5      0.0          test_loss = criterion(test_outputs, y)
    90         1      23332.9  23332.9      0.1          print(f'Test Loss: {test_loss.item():.4f}')
    91                                           
    92         1        120.5    120.5      0.0      print(f'total_timer : {total_timer.get_average_time()}')
    93         1        138.8    138.8      0.0      print(f'epoch_timer : {epoch_timer.get_average_time()}')

